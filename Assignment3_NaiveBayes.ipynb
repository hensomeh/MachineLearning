{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Assignment 3 - Naive Bayes</H1><br/>\n",
    "<table align='left'><tr><td><img src=\"./images/naiveBayesClassifier.jpeg\" alt=\"Naive Bayes Classifier\" style=\"width: 450px;text-align:left\"/></td></tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Iris flowers Dataset</h2>\n",
    "<h3><u/>Classes</u>- types of Iris flower</h3><br/><br/>\n",
    "<table align='left'>\n",
    "    <tr><div style=\"text-align:left;font-size:125%\"><u>There are 3 possible flower types:</u></div></tr>\n",
    "    <tr><th>class 0 - Iris Setosa</th><th>class 1 - Iris Virginica</th><th>class 2 - Iris Versicolor</th></tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./images/Iris-versicolor.jpg\" alt=\"Iris Versicolor\" style=\"width: 200px;text-align:left\"/></td>\n",
    "        <td><img src=\"./images/iris_setosa.jpg\" alt=\"Iris Setosa\" style=\"width: 200px;text-align:left\"/></td>\n",
    "        <td><img src=\"./images/iris_virginica.jpg\" alt=\"Iris Virginica\" style=\"width: 200px;text-align:left\"/></td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Feature Set</u></h3>\n",
    "<table align='left' width=\"200\">\n",
    "    <tr><td>\n",
    "        <img src=\"./images/iris_petal_sepal.png\" alt=\"Iris\" width=\"200\" align='left'/>\n",
    "    </td></tr>\n",
    "    <tr><td align='left'>\n",
    "        <div style=\"text-align:left;font-size:125%\"><u>Dataset includes 4 features</u>:</div><br/>\n",
    "        <ul style=\"list-style-type:circle;text-align:left;font-size:115%\">\n",
    "            <li>sepal-length</li>\n",
    "            <li>sepal-width</li>\n",
    "            <li>petal-length</li>\n",
    "            <li>petal-width</li>\n",
    "        </ul>\n",
    "    </td></tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignmet 3 - Naive Bayes (total of 10 points)\n",
    "<u>The assignment consists of 6 parts</u>:<br/>\n",
    "* a preceding step - import packages\n",
    "* Part 1 - Student information methods ----> needs stundent implementation\n",
    "* Part 2 - load the Iris dataset ----> run only\n",
    "* Part 3 - Training a (Guassian) Naive bayes model  ----> needs stundent implementation - 5 point\n",
    "  * Part 3a - Calculate Priors ----> needs stundent implementation - total 1 point\n",
    "  * Part 3b - Calculate Gaussian Likelihood 'mean' parameter ---->  needs stundent implementation - total 1 point\n",
    "  * Part 3c - Calculate Gaussian Likelihood 'std' parameter ---->  needs stundent implementation - total 1 point\n",
    "  * Part 3d - the \"fit\" method (main training flow) ----> needs stundent implementation - total 2 points\n",
    "* Part 4 - predict  ----> needs stundent implementation- total 4 points\n",
    "  * Part 4a - Calculate Guassian likelihood probability ----> run only\n",
    "  * Part 4b - Calculate a posteriori probabilities ---->  needs stundent implementation - total 2 points\n",
    "  * Part 4c - predict (main flow) ---->  needs stundent implementation - total 2 points\n",
    "* Part 5 - evaluation - calculate error rate  ---->  needs stundent implementation - total 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from random import randrange\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 1 - Student information methods:</h3><br/>\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b><br/><br/>\n",
    "<table align='left'>\n",
    "    <tr><td>\n",
    "        <img src=\"./images/id-card.png\" alt=\"name and id\" width=\"150\" align='left'/>\n",
    "    </td></tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myName</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your full name (as a string)\n",
    "    For example: assume your name is John Smith, you should write:\n",
    "    return 'John Smith'\n",
    "------------\n",
    "return value:\n",
    "- your full name (as a string)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c595f11fc929d4b77957a0c4ea39ebf3",
     "grade": false,
     "grade_id": "myName-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myName\n",
    "# --------------------------------------------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # YOUR CODE HERE\n",
    "    return \"Hen Haim Someh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myId</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your ID number (as an integer number)\n",
    "    For example: assume your ID number is 1234, you should write:\n",
    "    return 1234\n",
    "------------\n",
    "return value:\n",
    "- your ID number (as an integer number)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the 'YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd86e2e5bd34dbc752e47c5a08f57496",
     "grade": false,
     "grade_id": "myId-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myId\n",
    "# --------------------------------------------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    return 313468654"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information method - test</u><br/>\n",
    "* Test of 'myName' and 'myId' methods implementation  \n",
    "* It tests the correctness their implementation\n",
    "\n",
    "<u>Important Notes</u>:<br/>\n",
    "* This test cell MUST NOT raise any exception\n",
    "* It must pass all tests \n",
    "* Do NOT change or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9116a4635699caea101315f303d5461",
     "grade": false,
     "grade_id": "test-myName-myId",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'myName' method validation is successfull!\n",
      "your name is: Hen Haim Someh\n",
      "--------------------------------------\n",
      "'myId' method validation is successfull!\n",
      "your id is: 313468654\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test:\n",
    "## the 'myName' and the 'myId' methods implementation \n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 2 - Loading dataset - run only</h3>\n",
    "        <ul style=\"list-style-type:circle;text-align:left;font-size:115%\">\n",
    "            <li>load the Iris train & test datasets</li>\n",
    "        </ul>\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='left'/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b09711e11632fff98c0a1d2d038b64f3",
     "grade": false,
     "grade_id": "run-loading_iris_dataset",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 Iris classes\n",
      "iris classes:\n",
      "[\"0 (representing 'Setosa')\", \"1 (representing 'Versicolor')\", \"2 (representing 'Virginica')\"]\n",
      "\n",
      "There are 4 features in the feature set (each feature vector has a value for every feature)\n",
      "Feature names:\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "The train-set includes 120 instances (aka feature vectors)\n",
      "first few instances:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "index                                                           \n",
      "119                  6.0               2.2                5.0   \n",
      "128                  6.4               2.8                5.6   \n",
      "135                  7.7               3.0                6.1   \n",
      "91                   6.1               3.0                4.6   \n",
      "112                  6.8               3.0                5.5   \n",
      "\n",
      "       petal width (cm)  \n",
      "index                    \n",
      "119                 1.5  \n",
      "128                 2.1  \n",
      "135                 2.3  \n",
      "91                  1.4  \n",
      "112                 2.1  \n",
      "\n",
      "first few corresponding categories:\n",
      "index\n",
      "44     0\n",
      "103    2\n",
      "5      0\n",
      "20     0\n",
      "69     1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "### The Following section loads the iris dataset directly from sklean\n",
    "# --------------------------------------------------------\n",
    "# --- from sklearn import datasets\n",
    "# --- import os\n",
    "# --------------------------------------------------------\n",
    "# --- data_iris = datasets.load_iris()\n",
    "# --- dataset = pd.DataFrame(data_iris['data'], columns=data_iris['feature_names'])\n",
    "# --- dataset['target'] = data_iris['target']\n",
    "# --- dataset_shuffle = dataset.sample(frac=1, replace=False,random_state=41).reset_index()\n",
    "# --- dataset_shuffle.iloc[:120].to_csv('data'+os.sep+'iris_train_set.csv',index=False)\n",
    "# --- dataset_shuffle.iloc[120:].to_csv('data'+os.sep+'iris_test_set.csv',index=False)\n",
    "# --------------------------------------------------------\n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------------------------------------------\n",
    "# display the iris class information:\n",
    "# --------------------------------------------------------\n",
    "iris_classes = np.sort(np.unique(y_train.values))\n",
    "iris_class_names =  ('Setosa','Versicolor','Virginica')\n",
    "str_classes = [\"%d (representing '%s')\" %(iris_class,iris_class_names[iris_class]) for iris_class in iris_classes]\n",
    "print ('There are %d Iris classes' %(len(str_classes)))\n",
    "print ('iris classes:')\n",
    "print(str_classes)\n",
    "# --------------------------------------------------------\n",
    "# display the feature information:\n",
    "# --------------------------------------------------------\n",
    "feature_names = [col for col in x_train.columns]\n",
    "print ('\\nThere are %d features in the feature set (each feature vector has a value for every feature)' %(len(feature_names)))\n",
    "print('Feature names:')\n",
    "print(feature_names)\n",
    "# --------------------------------------------------------\n",
    "# display the first few rows of the dataset vectors:\n",
    "# --------------------------------------------------------\n",
    "print('\\nThe train-set includes %d instances (aka feature vectors)' %(x_train.shape[0]))\n",
    "print('first few instances:')\n",
    "print(x_train.head())\n",
    "print('\\nfirst few corresponding categories:')\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Training a (Guassian) Naive Bayes model\n",
    "\n",
    "<img src=\"./images/bayes.PNG\" alt=\"Naive Bayes Classifier\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Training a (Guassian) Naive bayes model ----> needs stundent implementation - 5  points\n",
    "  * Part 3a - Calculate Priors ----> needs stundent implementation - total 1 point\n",
    "  * Part 3b - Calculate Gaussian Likelihood 'mean' parameter ----> needs stundent implementation - total 1 point\n",
    "  * Part 3c - Calculate Gaussian Likelihood 'std' parameter ----> needs stundent implementation - total 1 point\n",
    "  * Part 3d - the \"fit\" method (main training flow) ----> needs stundent implementation - total 2 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3a - Calculate Priors \n",
    "for each class (0,1,2) you need to calculate the prior.<br/>\n",
    "* <b>prior(y=0)</b>=p(y=0)=count(y=0 in train-set)/count(number-of-instances in train-set)\n",
    "* <b> do this for each class (0,1,2) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 3a - Calculate class priors </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_category_priors</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return a (regular python) list \n",
    "containing the 3 classes prirors (one for each category).\n",
    "------------\n",
    "input parameter:\n",
    "- yTrain - the train-set categories\n",
    "------------\n",
    "return value:\n",
    "-  a (regular python) list, containing the priors of the classes\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "356ee712a3b5f00cfea34be3c3ff93ed",
     "grade": false,
     "grade_id": "calcCategoryPriors-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_category_priors\n",
    "# --------------------------------------------------------\n",
    "def calc_category_priors(yTrain):\n",
    "    unique_classes = np.sort(np.unique(yTrain.values))\n",
    "    # YOUR CODE HERE\n",
    "    priorsList = yTrain.value_counts()\n",
    "    numberOfInstances = len(yTrain)   \n",
    "    priorsArray = [float(priorsList[0]/numberOfInstances),\n",
    "                   float(priorsList[1]/numberOfInstances),\n",
    "                   float(priorsList[2]/numberOfInstances)]\n",
    "    return priorsArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5845d1d3e8c5242642cbf942008c8066",
     "grade": true,
     "grade_id": "test-calcCategoryPriors",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_category_priors' method ...\n",
      "\n",
      "prior for category 0: 0.341667\n",
      "\n",
      "----> This 'calc_category_priors' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_category_priors' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_category_priors' method ...\\n\") \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arrPriors = calc_category_priors(y_train)\n",
    "priorClass_0 = arrPriors[0]\n",
    "assert int(priorClass_0*100)==34,'wrong prior for class-0'\n",
    "print ('prior for category 0: %f' %(priorClass_0))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_category_priors' test passed successfully :-) \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - Calculate Gaussian Likelihood 'mean' parameter:\n",
    "for each feature calculate mean value for the feature in each for each of the class values (0,1,2) seperatly.<br/><br/>\n",
    "<b>for class 0 (y=0)</b> take the rows consisting 'target' value of 0, and calculate the mean <br/>\n",
    "To calculate mean use: dataframe[colName].mean() <br/><br/>\n",
    "<b>Do this for each feature for each class</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 3b - Calculate the 'mean' element out of likelihhod probability</u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_mean_likelihood</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return mean of the values of each feature\n",
    "this should be done seperatly for each class value (in the training set)\n",
    "    * create a meanDataframe, including the features as colums and classes as indexes\n",
    "    * the cells consists of the mean of distribution of feature values (given a specific class)\n",
    "------------\n",
    "input parameter:\n",
    "- training_set - the train-set dataframe\n",
    "------------\n",
    "return value:\n",
    "-  a dataframe, consisting of the feature names as colums and classes as indexes\n",
    "   the cells consists of the mean of distribution of feature values (given a specific class)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "812fa24182c1b29e139a6df2e9902df3",
     "grade": false,
     "grade_id": "calcMeanLikelihood-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_mean_likelihood\n",
    "# --------------------------------------------------------\n",
    "def calc_mean_likelihood(training_set):\n",
    "    # YOUR CODE HERE\n",
    "    dataFrameMeanArray = pd.DataFrame({ '0' : training_set[training_set['target'] == 0].mean(),\n",
    "                                        '1' : training_set[training_set['target'] == 1].mean(),\n",
    "                                        '2' : training_set[training_set['target'] == 2].mean()})\n",
    "    dataFrameMeanArray = dataFrameMeanArray.T\n",
    "    return dataFrameMeanArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc8e7f53878b09f6cab40b1f3c082724",
     "grade": true,
     "grade_id": "test-calcMeanLikelihood",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_mean_likelihood' method ...\n",
      "\n",
      "likelihood for the mean of petal length for category 1 is estimated as: 4.279487\n",
      "\n",
      "----> This 'calc_mean_likelihood' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_mean_likelihood' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_mean_likelihood' method ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "meanLiklihoodDf = calc_mean_likelihood(train_set)\n",
    "likelihood_petalLength_class1 = meanLiklihoodDf.iloc[1,2]\n",
    "assert int(likelihood_petalLength_class1*100)==427,'wrong mean likelihood estimation for petalLength_class1'\n",
    "print ('likelihood for the mean of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))\n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_mean_likelihood' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3c - Calculate Gaussian Likelihood 'std' parameter:\n",
    "for each feature calculate std value for the feature in each for each of the class values (0,1,2) seperatly.<br/><br/>\n",
    "<b>for class 0 (y=0)</b> take the rows consisting 'target' value of 0, and calculate the std <br/>\n",
    "To calculate std use: dataframe[colName].std() <br/><br/>\n",
    "<b>Do this for each feature for each class</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 3c - Calculate the 'std' element out of likelihhod probability</u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_std_likelihood</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return std (standard diviation) of the values of each feature\n",
    "this should be done seperatly for each class value (in the training set)\n",
    "    * create a stdDataframe, including the features as colums and classes as indexes\n",
    "    * the cells consists of the std of distribution of feature values (given a specific class)\n",
    "------------\n",
    "input parameter:\n",
    "- training_set - the train-set dataframe\n",
    "------------\n",
    "return value:\n",
    "-  a dataframe, consisting of the feature names as colums and classes as indexes\n",
    "   the cells consists of the std of distribution of feature values (given a specific class)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28fe71115f09b006e680a6114e4976cf",
     "grade": false,
     "grade_id": "calcStdLikelihood-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_std_likelihood\n",
    "# --------------------------------------------------------\n",
    "def calc_std_likelihood(training_set):\n",
    "    # YOUR CODE HERE\n",
    "    dataFrameStdArray = pd.DataFrame({ '0' : training_set[training_set['target'] == 0].std(),\n",
    "                                       '1' : training_set[training_set['target'] == 1].std(),\n",
    "                                       '2' : training_set[training_set['target'] == 2].std()})\n",
    "    dataFrameStdArray = dataFrameStdArray.T\n",
    "    return dataFrameStdArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09ca2b5fb1a0cb8a23612e5c7abb196f",
     "grade": true,
     "grade_id": "test-calcStdLikelihood",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_std_likelihood' method ...\n",
      "\n",
      "likelihood for the std of petal length for category 1 is estimated as: 0.501146\n",
      "\n",
      "----> This 'calc_std_likelihood' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_std_likelihood' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_std_likelihood' method ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "stdLiklihoodDf = calc_std_likelihood(train_set)\n",
    "likelihood_petalLength_class1 = stdLiklihoodDf.iloc[1,2]\n",
    "assert int(likelihood_petalLength_class1*1000)==501,'wrong std likelihood estimation for petalLength_class1'\n",
    "print ('likelihood for the std of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_std_likelihood' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3d - the fit method:\n",
    "The fit method uses the previous 3 methods for a full (Gaussian) Naive Bayes model training step.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 3d - <b>fit</b> - Naive Bayes main training flow</u> ----> needs stundent implementation - 2 point<br/>\n",
    "<u>method name</u>: <b>fit</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the 3 products of the Naive Bayes training.\n",
    "Note: this step is called the 'fit' api in machine learning.\n",
    "The method needs to calculate and return the products from the 3 previous methods you've \n",
    "implemented in the previous cells, including calc_category_priors, calc_mean_likelihood, calc_std_likelihood.\n",
    "Please check the expected output for these methods.\n",
    "------------\n",
    "input parameter:\n",
    "- training_set - the train-set dataframe\n",
    "------------\n",
    "return values (comma seperated):\n",
    "- lst_class_prior    - output from calc_category_priors\n",
    "- df_mean_likelihood - output from calc_mean_likelihood\n",
    "- df_std_likelihood  - output from calc_std_likelihood\n",
    "return statememt (assuming the same variable names):\n",
    "return lst_class_prior,df_mean_likelihood,df_std_likelihood\n",
    "-----\n",
    "note the return statement should be done as following (assuming these are the names of the variables):\n",
    "return lst_class_prior,df_mean_likelihood,df_std_likelihood\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94baba267e8f0f8a4bf1981767f89788",
     "grade": false,
     "grade_id": "fit-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: fit\n",
    "# --------------------------------------------------------\n",
    "def fit(training_set):\n",
    "    # YOUR CODE HERE\n",
    "    return (calc_category_priors(training_set['target']), calc_mean_likelihood(training_set), calc_std_likelihood(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1b679c9d608d01daa88b80cb934def8",
     "grade": true,
     "grade_id": "test-fit",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'fit' method #1 ...\n",
      "\n",
      "prior for category 2: 0.333333\n",
      "likelihood for the mean of sepal width for category 2 is estimated as: 2.945000\n",
      "likelihood for the std of sepal width for category 2 is estimated as: 0.314561\n",
      "\n",
      "----> This 'calc_std_likelihood' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'fit' method #1 ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arrPriors, meanLiklihoodDf, stdLiklihoodDf = fit(train_set)\n",
    "priorClass_2 = arrPriors[2]\n",
    "likelihood_mean_sepalWidth_class2 = meanLiklihoodDf.iloc[2,1]\n",
    "likelihood_std_sepalWidth_class2 = stdLiklihoodDf.iloc[2,1]\n",
    "assert int(priorClass_2*100)==33,'wrong prior for class-2'\n",
    "print ('prior for category 2: %f' %(priorClass_2))\n",
    "assert int(likelihood_mean_sepalWidth_class2*10)==29,'wrong mean likelihood estimation for sepalWidth_class2'\n",
    "print ('likelihood for the mean of sepal width for category 2 is estimated as: %f' %(likelihood_mean_sepalWidth_class2))\n",
    "assert int(likelihood_std_sepalWidth_class2*100)==31,'wrong std likelihood estimation for sepalWidth_class2'\n",
    "print ('likelihood for the std of sepal width for category 2 is estimated as: %f' %(likelihood_std_sepalWidth_class2))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_std_likelihood' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb261d5b67e34c7efff9890afe5af2de",
     "grade": true,
     "grade_id": "test-fit-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'fit' method #2, this test is not visble to the students ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'fit' method #2, this test is not visble to the students ...\\n\") \n",
    "# --------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - predict ----> needs stundent implementation- total 4 points\n",
    "  * Part 4a - Calculate Guassian likelihood probability ----> run only\n",
    "  * Part 4b - Calculate a posteriori probabilities ----> needs stundent implementation - total 2 points\n",
    "  * Part 4c - prdict ----> needs stundent implementation - total 2 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/bayes.PNG\" alt=\"Naive Bayes Classifier\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 4a  - the 'calcGaussianProb' method:\n",
    "The 'calcGaussianProb' method uses the training methods and returns the Gaussian probablilty <br/>\n",
    "of that feature value (for a specifc class).<br/>\n",
    "##### Note: you NEED to run this cell (but NOT implement anything)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/gausianProb.PNG\" alt=\"Gausian likelihood probability\" align='left'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\"\"\"\n",
    "given a specific feature value and the trained mean & std (per a specific class) \n",
    "We assume normal (Guassian distribution) and we return the density value \n",
    "or the Gaussian Probability for that given value\n",
    "Note: the input parameters are all numbers (scalars)\n",
    "\"\"\"\n",
    "def calc_gaussian_prob(x_feature_val, feature_mean, feature_std):\n",
    "    exponent = np.exp(-((x_feature_val-feature_mean)**2 / (2 * feature_std**2 )))\n",
    "    return (1 / ((2 * np.pi)**(1/2) * feature_std)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4b - the 'calc_aposterior_probs' method:\n",
    "The 'calc_aposterior_probs' method uses the training parameters to predict the a posteriori probability <br/>\n",
    "for every test instance, per class <br/>\n",
    "##### Note: you NEED to run this cell (but NOT implement anything)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 4b - calculate Aposterior probabilities</u> ----> needs stundent implementation - 2 point<br/>\n",
    "<u>method name</u>: <b>calc_aposterior_probs</b><br/>\n",
    "\n",
    "<pre>\n",
    "The following function should create a probability matrix to store the results.\n",
    "To do that create a dataframe with the categories as columns and test indexes ans indexes.\n",
    "The value of the cells should be a multiplication between the class prior and the Gausian probabilities of all the features (using the  'calcGaussianProb' method) for the specific test feature vectore (i.e., Gausian probabilities for feature values of every row).\n",
    "The outcome is the Aposterior probabilities for each feature vector (one for each class). \n",
    "Please check the expected output for these methods.\n",
    "------------\n",
    "input parameter:\n",
    "- x_test - the test-set instances\n",
    "- arr_trained_class_priors - the trained priors of the classes\n",
    "- df_trained_mean - the dataframe of the trained means for each feature per each class\n",
    "- df_trained_std - the dataframe of the trained stds for each feature per each class\n",
    "- categories - the possible categories simple python list.\n",
    "               remark: in the iris case includes [0,1,2]\n",
    "------------\n",
    "return value:\n",
    "------------\n",
    "- df_aposterior_probs -  a dataframe containing posterior probabilities per class, per test feature vector.\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c61a44351594be366032d5ccfdbd39",
     "grade": false,
     "grade_id": "calc_aposterior_probs-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_aposterior_probs\n",
    "# --------------------------------------------------------\n",
    "def calc_aposterior_probs(x_test, arr_trained_class_priors, df_trained_mean, df_trained_std, categories):\n",
    "    num_classes = len(categories)\n",
    "    df_prob_per_test_inst_per_class = pd.DataFrame(np.zeros((x_test.shape[0], num_classes)), columns=categories, index=x_test.index)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for category in categories:\n",
    "        df_prob_per_test_inst_per_class[category] = arr_trained_class_priors[category]\n",
    "        \n",
    "        for row in range(0, x_test.shape[0]):    \n",
    "            for column in range(0, x_test.shape[1]):\n",
    "                df_prob_per_test_inst_per_class.iloc[row, category] *= calc_gaussian_prob(x_test.iloc[row, column],\n",
    "                                                                                          df_trained_mean.iloc[category, column],\n",
    "                                                                                          df_trained_std.iloc[category, column])        \n",
    "    return df_prob_per_test_inst_per_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8c2b70ad5203aefb4d15068cb4dd380",
     "grade": true,
     "grade_id": "test-calc_aposterior_probs",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_aposterior_probs' method #1 ...\n",
      "\n",
      "aposterior probability of row with index 103 (2nd row), class 2: 0.207558\n",
      "\n",
      "----> This 'calc_aposterior_probs' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_aposterior_probs' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_aposterior_probs' method #1 ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arr_trained_priors = calc_category_priors(y_train)\n",
    "trained_mean_df = calc_mean_likelihood(train_set)\n",
    "trained_std_df = calc_std_likelihood(train_set)\n",
    "unique_categories = np.sort(np.unique(y_train.values))\n",
    "\n",
    "df_prob_per_test_inst_per_class = calc_aposterior_probs(x_test, arr_trained_priors, trained_mean_df, trained_std_df, unique_categories)\n",
    "assert isinstance(df_prob_per_test_inst_per_class,pd.DataFrame),'calc_aposterior_probs should return a dataframe'\n",
    "assert df_prob_per_test_inst_per_class.shape[0]==x_test.shape[0],'calc_aposterior_probs should return a dataframe with %d rows' %(x_test.shape[0])\n",
    "assert df_prob_per_test_inst_per_class.shape[1]==len(unique_categories),'calc_aposterior_probs should return a dataframe with %d columns' %(len(unique_categories))\n",
    "assert int( df_prob_per_test_inst_per_class.loc[103,2]*1000)==207,'wrong aposterior probability for class: 2, index: 103'\n",
    "print('aposterior probability of row with index 103 (2nd row), class 2: %f' %(df_prob_per_test_inst_per_class.loc[103,2]))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_aposterior_probs' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53a99ed74696acfdc197dffd378ffeaf",
     "grade": true,
     "grade_id": "test-calc_aposterior_probs-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_aposterior_probs' method #1 ...\n",
      "\n",
      "aposterior probability of row with index 44 (1st row), class 0: 0.013257\n",
      "\n",
      "----> This 'calc_aposterior_probs' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_aposterior_probs' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_aposterior_probs' method #1 ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arr_trained_priors = calc_category_priors(y_train)\n",
    "trained_mean_df = calc_mean_likelihood(train_set)\n",
    "trained_std_df = calc_std_likelihood(train_set)\n",
    "unique_categories = np.sort(np.unique(y_train.values))\n",
    "\n",
    "df_prob_per_test_inst_per_class = calc_aposterior_probs(x_test, arr_trained_priors, trained_mean_df, trained_std_df, unique_categories)\n",
    "#print (df_prob_per_test_inst_per_class.where(df_prob_per_test_inst_per_class>0.01).head())\n",
    "assert isinstance(df_prob_per_test_inst_per_class,pd.DataFrame),'calc_aposterior_probs should return a dataframe'\n",
    "assert df_prob_per_test_inst_per_class.shape[0]==x_test.shape[0],'calc_aposterior_probs should return a dataframe with %d rows' %(x_test.shape[0])\n",
    "assert df_prob_per_test_inst_per_class.shape[1]==len(unique_categories),'calc_aposterior_probs should return a dataframe with %d columns' %(len(unique_categories))\n",
    "assert int( df_prob_per_test_inst_per_class.loc[44,0]*1000)==13,'wrong aposterior probability for class: 0, index: 44'\n",
    "print('aposterior probability of row with index 44 (1st row), class 0: %f' %(df_prob_per_test_inst_per_class.loc[44,0]))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_aposterior_probs' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4c- the 'predict' method:\n",
    "The 'predict' method is a Guasian Naive Bayes classifier <br/>\n",
    "Use the previous method (calc_aposterior_probs), to calculate  a posteriori probabilites <br/>\n",
    "for every test instance.\n",
    "And calculate the most probable class for each test instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 4c - predict </u> ----> needs stundent implementation - 2 point<br/>\n",
    "<u>method name</u>: <b>predict</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the predicted categories of the test set examples\n",
    "one category for each correcponding test instance\n",
    "this should be done seperatly for each class value (in the training set), using the Gaussian Naive Bayes.\n",
    "Note: For each test veture vector, use the Aposterior Probability for each class. \n",
    "      The predicted class (in the example level), should be the one with the maximum probability.\n",
    "------------\n",
    "input parameter:\n",
    "- x_test - the test-set instances\n",
    "- arr_trained_class_priors - the trained priors of the classes\n",
    "- df_trained_mean - the dataframe of the trained means for each feature per each class\n",
    "- df_trained_std - the dataframe of the trained stds for each feature per each class\n",
    "- categories - the possible categories simple python list.\n",
    "               remark: in the iris case includes [0,1,2]\n",
    "------------\n",
    "return value:\n",
    "------------\n",
    "- y_predicted -  a series of containing all predicted class values per test instance\n",
    "---------------------\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4abe21987fd9d39f7bce766b789a079",
     "grade": false,
     "grade_id": "predict-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: predict\n",
    "# --------------------------------------------------------\n",
    "def predict(x_test, arr_trained_class_priors, df_trained_mean, df_trained_std, categories):\n",
    "    # YOUR CODE HERE\n",
    "    dataFramePosterior = calc_aposterior_probs(x_test, arr_trained_class_priors, df_trained_mean, df_trained_std, categories)\n",
    "    return dataFramePosterior.idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "507bb24846574631d0d40799342e1655",
     "grade": true,
     "grade_id": "test-predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'predict' method #1 ...\n",
      "\n",
      "y_predicted first few rows:\n",
      "index\n",
      "44     0\n",
      "103    2\n",
      "5      0\n",
      "20     0\n",
      "69     1\n",
      "dtype: int64\n",
      "\n",
      "----> This 'predict' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'predict' method #1 ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arr_trained_priors = calc_category_priors(y_train)\n",
    "trained_mean_df = calc_mean_likelihood(train_set)\n",
    "trained_std_df = calc_std_likelihood(train_set)\n",
    "unique_categories = np.sort(np.unique(y_train.values))\n",
    "y_predicted = predict(x_test, arr_trained_priors, trained_mean_df, trained_std_df, unique_categories)\n",
    "\n",
    "assert isinstance(y_predicted,pd.Series),'predict should return a series'\n",
    "assert y_predicted.shape[0]==y_test.shape[0],'predict should return a series with %d rows' %(y_test.shape[0])\n",
    "assert y_predicted.loc[44]==0,'wrong predicted value for index 44 (first value), expects: 0'\n",
    "assert y_predicted.iloc[4]==1,'wrong predicted value for 5th value, expects: 1'\n",
    "print ('y_predicted first few rows:')\n",
    "print (y_predicted.head())\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'predict' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77319b44cfa3dc43d5c71add3cf6401d",
     "grade": true,
     "grade_id": "test-predict-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'predict' method #2, this test is not visble to the students ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'predict' method #2, this test is not visble to the students ...\\n\") \n",
    "# --------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - evaluation (error rate) ----> needs stundent implementation - 1 point\n",
    "<img src=\"./images/inaccuracy.jpg\" alt=\"Accuracy\" width=\"300\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 5 - Evaluation (error rate) </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_error_rate</b><br/>\n",
    "\n",
    "<pre>\n",
    "The following is expected:\n",
    "- the method needs to return the error rate (incorrectly predicted ratio)\n",
    "------------\n",
    "input parameter:\n",
    "- y_predicted -  a series of containing all predicted class values per test instance\n",
    "- y_test - a series of containing all actual class values per test instance\n",
    "------------\n",
    "return value:\n",
    "------------\n",
    "- errorRateVal - the error rate value\n",
    "---------------------\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75d347acae833ed2f91a744d3d2fc31f",
     "grade": false,
     "grade_id": "calc_error_rate-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_error_rate\n",
    "# --------------------------------------------------------\n",
    "def calc_error_rate(y_predicted,y_test):\n",
    "    # YOUR CODE HERE\n",
    "    errorRate = 0   \n",
    "    for i in range (0, y_predicted.shape[0]):\n",
    "        if (y_test.iloc[i] != y_predicted.iloc[i]):\n",
    "            errorRate = errorRate + 1\n",
    "            \n",
    "    errorRate = errorRate / y_predicted.shape[0]\n",
    "    return errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "474c6de2dd135c22a42441fe3da5626b",
     "grade": true,
     "grade_id": "test-error_rate",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing implementation of the 'calc_error_rate' method ...\n",
      "\n",
      "Error Rate: 0.0\n",
      "\n",
      "----> This 'calc_error_rate' test passed successfully :-) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_error_rate' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'calc_error_rate' method ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------- \n",
    "train_set = pd.read_csv('data'+os.sep+'iris_train_set.csv').set_index('index')\n",
    "x_train = train_set.drop('target', axis=1)\n",
    "y_train = train_set['target']\n",
    "# ----\n",
    "test_set  = pd.read_csv('data'+os.sep+'iris_test_set.csv').set_index('index')\n",
    "x_test = test_set.drop('target', axis=1)\n",
    "y_test = test_set['target']\n",
    "# --------------------- \n",
    "arr_trained_priors = calc_category_priors(y_train)\n",
    "trained_mean_df = calc_mean_likelihood(train_set)\n",
    "trained_std_df = calc_std_likelihood(train_set)\n",
    "unique_categories = np.sort(np.unique(y_train.values))\n",
    "y_predicted = predict(x_test, arr_trained_priors, trained_mean_df, trained_std_df, unique_categories)\n",
    "error_rate = calc_error_rate(y_predicted,y_test)\n",
    "assert float(int(error_rate*1000))/1000 == 0, \"error rate should be 0\"\n",
    "print(\"Error Rate: {}\".format(error_rate))\n",
    "# --------------------------------------------------------\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'calc_error_rate' test passed successfully :-) \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
