{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Linear Regression with Gradient Descent  \n",
    "\n",
    "<img src=\"./images/gradientDescent_animation.gif\" alt=\"Linear Regression w/Gradient Descent\" width=\"600\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The submition - important notes\n",
    "### You must follow the rules described here, regarding assignment submission:  \n",
    "* <b> Work by yourself</b> and submit your own assignment, <b>no pairing</b> to other students\n",
    "* Test and save your assignment - <b>submit the last tested and saved version</b>\n",
    "* Work on the <b>original notebook</b> of the assignmen \n",
    "* do <b>NOT</b> submit an <b>empty assignment</b> \n",
    "* do <b>NOT add extra files</b> \n",
    "* submit <b>only</b> the <b>notebook (.ipynb)</b> file and <u>NOT a .py/.txt/.rar/.zip</u> file and so on\n",
    "* <b>do NOT change</b> the notebook file name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assignment relates to 2 datasets:\n",
    "* a simple dataset with 2 columns: 'attr','target'\n",
    "  * It will be used for training 1D linear regression model\n",
    "* An additional dataset, re: house prices\n",
    "  * It will be used for training a multivariant linear regression model\n",
    "* You will also need to implement other functions, such as a function for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5 - Linear Regression with Gradient Descent (total possible points: 10 points)\n",
    "<u>The assignment consists of 6 parts</u>:<br/>\n",
    "* a preceding step - import packages\n",
    "* Part 1 - Student information methods ----> needs stundent implementation\n",
    "* Part 2 - univariate (1D) linear regression with gradient descent - 4 points\n",
    "  * part 2a - load and display the '2D' dataset ----> run only\n",
    "  * part 2b - univariate_predict ----> Student's implementation - total 1 point\n",
    "  * part 2c - univariate_fit ----> Student's implementation - total 3 points\n",
    "* Part 3 - The Dataset - House pricing - 5 points\n",
    "  * Part 3a - load the house pricing dataset ----> run only\n",
    "  * part 3b - scale and de-scale data using t-score (remove mean, divide std) ----> run only\n",
    "  * Part 3c - add fictive attribute to x_feature_vector ----> run only\n",
    "  * Part 3d - multivariate linear regression - predict ----> Student's implementation - total 1 point\n",
    "  * Part 3e - multivariate linear regression training with gradient descent ----> total 4 points\n",
    "* Part 4 - Evaluation - RMSE - Root Mean Square Error  ----> Student's implementation - total 1 point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "import math\n",
    "import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Note: do NOT add imports, such as sklearn, which could\n",
    "# answer the following questions.\n",
    "# --- add your imports here IF NEEDED:\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 1 - Student information methods:</h3><br/>\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b><br/><br/>\n",
    "<table align='left'>\n",
    "    <tr><td>\n",
    "        <img src=\"./images/id-card.png\" alt=\"name and id\" width=\"150\" align='left'/>\n",
    "    </td></tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myName</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your full name (as a string)\n",
    "    For example: assume your name is John Smith, you should write:\n",
    "    return 'John Smith'\n",
    "------------\n",
    "return value:\n",
    "- your full name (as a string)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c595f11fc929d4b77957a0c4ea39ebf3",
     "grade": false,
     "grade_id": "myName-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myName\n",
    "# --------------------------------------------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myId</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your ID number (as an integer number)\n",
    "    For example: assume your ID number is 1234, you should write:\n",
    "    return 1234\n",
    "------------\n",
    "return value:\n",
    "- your ID number (as an integer number)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the 'YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd86e2e5bd34dbc752e47c5a08f57496",
     "grade": false,
     "grade_id": "myId-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myId\n",
    "# --------------------------------------------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information method - test</u><br/>\n",
    "* Test of 'myName' and 'myId' methods implementation  \n",
    "* It tests the correctness their implementation\n",
    "\n",
    "<u>Important Notes</u>:<br/>\n",
    "* This test cell MUST NOT raise any exception\n",
    "* It must pass all tests \n",
    "* Do NOT change or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9116a4635699caea101315f303d5461",
     "grade": false,
     "grade_id": "test-myName-myId",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test:\n",
    "## the 'myName' and the 'myId' methods implementation \n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Dataset 1 - 2D dataset\n",
    "* includes 2 columns: \n",
    "  * attr   - the attribute to use (a singe attribute x1 for every feature vector)\n",
    "  * target - the actual value (y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2a - load  dataset 1 ----> run only\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6c27fd03921c688c48bdd1ca0ccfeb9",
     "grade": false,
     "grade_id": "run-load-2d-dataset",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following loads the dataset\n",
    "print ('Loading the multivariate 2D dataset (dataset-1) ...')\n",
    "df_1d_attr_target = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_train1.csv')\n",
    "X_vectors = df_1d_attr_target.drop('target',axis=1)\n",
    "y_categories = df_1d_attr_target['target']\n",
    "plt.scatter(X_vectors, y_categories)\n",
    "plt.show()\n",
    "df_1d_attr_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a352bb7d86574a1ee7eb5fee39737266",
     "grade": false,
     "grade_id": "run-2d-dataset-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# describe dataset\n",
    "df_1d_attr_target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2b  - univariate predict ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 2b - univariate linear regression predict </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>univariate_predict</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to calculate and return the predicted values, for the given model (with w_0, w_1).\n",
    "This is done using the univariate linear regression model y_hat=w0+w1*x1.\n",
    "------------\n",
    "input parameters:\n",
    "- x_feature_vectors - a dataframe containing all feature vectors for which we want to predict the y_hat values,\n",
    "              using the univariat (one feature) linear regression model\n",
    "    note: x_feature_vectors could be the training feature vectors for interim stages of training, or \n",
    "          the test feature vectots for real predictions \n",
    "- w_0 - the w_0 parameter of the linear regression model\n",
    "- w_1 - the w_1 parameter of the linear regression model\n",
    "    note: w_0, w_1 could be interim value, during training, or final values for testing.\n",
    "------------\n",
    "return value:\n",
    "- y_hat - a series of the predictions for each input instance \n",
    "  notes:\n",
    "        * the y_hat prediction vector could be of an intermediate model during training or \n",
    "        for prediction of new examples during evaluation\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f405120caa6305d208174807953c9afc",
     "grade": false,
     "grade_id": "univariate_predict-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: univariate_predict\n",
    "# --------------------------------------------------------\n",
    "def univariate_predict(x_feature_vectors, w_0, w_1):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f644ad03b1e53e5459b0b9adc2cc5d2",
     "grade": false,
     "grade_id": "visualize_univariate_predict",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# VISUALIZATION ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Visualization for the:\n",
    "## 'univariate_predict' method output \n",
    "# --------------------------------------------------------\n",
    "def plotPointsAndLine(x1Series,y_Series,y_Hat):\n",
    "    # Plot the values\n",
    "    plt.scatter(x1Series, y_Series, c = 'b', marker='o')\n",
    "    plt.xlabel('attribute (x1)')\n",
    "    plt.ylabel('target (y)')\n",
    "    plt.plot([min(x1Series), max(x1Series)], [min(y_Hat), max(y_Hat)], color='red') \n",
    "    plt.show()    \n",
    "# --------------------------------------------------------\n",
    "\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "yHat = None\n",
    "# --------------------------------------------------------\n",
    "df_1d_attr_target_train = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_train1.csv')\n",
    "df_1d_attr_target_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_test1.csv')\n",
    "X_vectors = df_1d_attr_target_train.drop('target',axis=1)\n",
    "y_categories = df_1d_attr_target_train['target']\n",
    "yHat = univariate_predict(df_1d_attr_target_train, 5, 1)\n",
    "\n",
    "x1TrainSeries = X_vectors.iloc[:,-1]\n",
    "print('show some model and how it fits the data:')\n",
    "plotPointsAndLine(x1TrainSeries,y_categories,yHat)\n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f107995115bd6ea4245a57d0a21d0f1",
     "grade": true,
     "grade_id": "test-univariate_predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'univariate_predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'univariate_predict' method ...\\n\") \n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "df_1d_attr_target_train = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_train1.csv')\n",
    "df_1d_attr_target_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_test1.csv')\n",
    "X_train = df_1d_attr_target_train.drop('target',axis=1)\n",
    "y_train = df_1d_attr_target_train['target']\n",
    "X_test = df_1d_attr_target_test.drop('target',axis=1)\n",
    "y_test = df_1d_attr_target_test['target']\n",
    "# --------------------------------------------------------\n",
    "\n",
    "yHat = univariate_predict(X_train, 2, 1)\n",
    "assert [int(val) for val in yHat.iloc[0:3]]==[43, 34, 52], 'wrong values from linear regression output'\n",
    "\n",
    "print (\"----> This 'univariate_predict' test passed successfully :-) \\n\")\n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2c - univariate linear regression with gradient descent  \n",
    "<img src=\"./images/opt_momentum.png\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2c - univariate linear regression with gradient descent ----> Student's implementation - total 3 points\n",
    "<img src=\"./images/univariate-gradient-descent.png\" alt=\"univariate gradient-descent\" width=\"600\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Part 2c - univariate linear regression fit </u> ----> needs stundent implementation - 3 points<br/>\n",
    "<u>method name</u>: <b>univariate_fit</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following method to train a univariate (one feature) linear regression model, \n",
    "using the gradient descent algorithm.        \n",
    "------------\n",
    "input parameters:\n",
    "- X_train - a dataframe containing all feature vectors of the train set.\n",
    "- y_train - a series of containing all class values per train instance.\n",
    "- w_0_initiail - the initial value of w0 \n",
    "- w_1_initiail - the initial value of w1\n",
    "- alpha - the learning rate\n",
    "- num_iterations - number of iterations to run gadient descent    \n",
    "------------\n",
    "return values (comma seperated):\n",
    "- w_0_trained - the trained value of w_o\n",
    "- w_1_trained - the trained value of w_1\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb621076845a1b462c837399e524b958",
     "grade": false,
     "grade_id": "univariate_fit-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 3\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: univariate_fit\n",
    "# --------------------------------------------------------\n",
    "def univariate_fit(X_train,y_train,w_0_initiail,w_1_initiail,alpha,num_iterations):\n",
    "    ## use partialDerivative_w0_w1_ForTrainset\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cb954ffb4a61de305fef6ec6eb2f560",
     "grade": true,
     "grade_id": "test1-univariate_fit",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'univariate_fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#---------------------\n",
    "print (\"test #1 - basic test of 'univariate_fit' method for instances ...\\n\") \n",
    "#---------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "df_1d_attr_target_train = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_train1.csv')\n",
    "df_1d_attr_target_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_test1.csv')\n",
    "X_train = df_1d_attr_target_train.drop('target',axis=1)\n",
    "y_train = df_1d_attr_target_train['target']\n",
    "X_test = df_1d_attr_target_test.drop('target',axis=1)\n",
    "y_test = df_1d_attr_target_test['target']\n",
    "# --------------------------------------------------------\n",
    "trained_w0, trained_w1 = univariate_fit(X_train,y_train,0,0,0.00001,10)\n",
    "assert (int(trained_w0*1000),int(trained_w1*100))==(11, 57), 'wrong values for univariate_fit'\n",
    "print ('trained (10 epoch) wo,w1 = (%f,%f), plot on train points:' %(trained_w0, trained_w1))\n",
    "x1TrainSeries = X_train.iloc[:,-1]\n",
    "yHat=univariate_predict(X_train, trained_w0, trained_w1)\n",
    "plotPointsAndLine(x1TrainSeries,y_train,yHat)\n",
    "\n",
    "print (\"\\n----> The #1 'univariate_fit' test passed successfully :-) \\n\")\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "#-------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4cd1963486a1e72844191219936ef58",
     "grade": true,
     "grade_id": "test2-univariate_fit",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'univariate_fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#---------------------\n",
    "print (\"test #2 - basic test of 'univariate_fit' method for instances ...\\n\") \n",
    "#---------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "df_1d_attr_target_train = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_train1.csv')\n",
    "df_1d_attr_target_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'2d_data_test1.csv')\n",
    "X_train = df_1d_attr_target_train.drop('target',axis=1)\n",
    "y_train = df_1d_attr_target_train['target']\n",
    "X_test = df_1d_attr_target_test.drop('target',axis=1)\n",
    "y_test = df_1d_attr_target_test['target']\n",
    "# --------------------------------------------------------\n",
    "trained_w0, trained_w1 = univariate_fit(X_train,y_train,1,5,0.00001,100)\n",
    "assert (int(trained_w0*100),int(trained_w1*100))==(93, 148), 'wrong values for univariate_fit'\n",
    "print ('trained (100 epochs) wo,w1 = (%f,%f), plot on train points:' %(trained_w0, trained_w1))\n",
    "yHat=univariate_predict(X_train, trained_w0, trained_w1)\n",
    "x1TrainSeries = X_train.iloc[:,-1]\n",
    "plotPointsAndLine(x1TrainSeries,y_train,yHat)\n",
    "\n",
    "print (\"\\n----> The #2 'univariate_fit' test passed successfully :-) \\n\")\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "#-------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0bda2562a4f9a78efa4d1e4cf72d350",
     "grade": true,
     "grade_id": "test3-univariate_fit-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'univariate_fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------- \n",
    "print (\"test #3 - test of the 'univariate_fit' method, this test is not visble to the students ...\\n\") \n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - The Dataset - House pricing - 5 points\n",
    "<img src='./images/For-sale-sign.jpg' alt=\"The Dataset - House pricing\" style=\"width: 150x\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar houses should be similar in price\n",
    "Expected to share similar attributes:<br/>\n",
    "* Square footage\n",
    "* Number of bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3a - load the house pricing dataset - run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea758995fade7fbd5d4b193bf380f7c9",
     "grade": false,
     "grade_id": "run-load-housePrice_data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def plotPointsAndPricingLine(x_dataframe,y_Series,y_Hat):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax = Axes3D(fig)\n",
    "    # Generate the values\n",
    "    x1_vals = x_dataframe.iloc[:, 0]\n",
    "    x2_vals = x_dataframe.iloc[:, 1]\n",
    "    y_vals = y_Series.iloc[:]/1000\n",
    "\n",
    "    ax.scatter(x1_vals, x2_vals, y_vals, c = 'b', marker='o')\n",
    "    ax.set_xlabel('size (feet^2)')\n",
    "    ax.set_ylabel('#rooms')\n",
    "    ax.set_zlabel('Price($K)')\n",
    "    \n",
    "    if y_Hat is not None:\n",
    "        ax.plot([min(x1_vals), max(x1_vals)], [min(x2_vals), max(x2_vals)],  [min(y_Hat/1000), max(y_Hat/1000)], color='red') \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following loads the house pricing dataset\n",
    "print ('Loading the multivariate house pricing (2 features) dataset (dataset-2) ...')\n",
    "df_house_pricing = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "X_vectors = df_house_pricing.drop('price',axis=1)\n",
    "y_categories = df_house_pricing['price']\n",
    "\n",
    "print ('displaying data: \\n')\n",
    "plotPointsAndPricingLine(X_vectors, y_categories,None) # y_categories)\n",
    "\n",
    "df_house_pricing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6cc753b9b7e3f7555f628b9716be18",
     "grade": false,
     "grade_id": "desc-load-housePrice_data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "df_house_pricing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3b - scale and de-scale data using t-score (remove mean, divide std) ----> run only\n",
    "<img src=\"./images/var_std_in_sample.png\" alt=\"var in sample\" style=\"width: 250px;\"/>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a5d808af609976bc260ac0e48cf8597",
     "grade": false,
     "grade_id": "run-scale-descale",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method1 name: t_distibution_mean_std\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# --- get the mean and std of the series\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - series - the input series to be scaled\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - mean_series - the mean value of the series \n",
    "# - std_series - the std value of the series (sample std as shown in the above figure, NOT population std)\n",
    "# --------------------------------------------------------\n",
    "def t_distibution_mean_std(series): \n",
    "    mean_series = series.mean()\n",
    "    n_minus_1=series.shape[0]-1\n",
    "    dist_from_mean = series-mean_series\n",
    "    std_series  = math.sqrt((dist_from_mean*dist_from_mean).sum()/n_minus_1)\n",
    "    return [mean_series,std_series]\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method2 name: t_distibution\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# --- get a dataframe consisting of the mean and std of each column in the dataset.\n",
    "# --- Notes: - the columns of the output dataframes correspond to the columns of the input dataframe\n",
    "#            - the 1st and 2nd rows (indexes) consist of the mean and std respectivly.\n",
    "#            - the std values consists of the sample std as shown in the above figure (and NOT the population std).\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - trainset - an input dataframe of the train set including both the X feature vectors and y categories to be scaled\n",
    "#              note: that the distribution is calculated on the trainset only and used both for train and test sets\n",
    "#                    for scaling.\n",
    "# ------------\n",
    "# return value:\n",
    "# - mean_std_dataframe - a dataframe including the mean and std for each column \n",
    "# --------------------------------------------------------\n",
    "def t_distibution(trainset):\n",
    "    mean_std_dataframe = pd.DataFrame(columns=trainset.columns,index=['mean','std'])\n",
    "    for col in trainset.columns:\n",
    "        mean_std_dataframe[col]=t_distibution_mean_std(trainset[col])\n",
    "    return mean_std_dataframe\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method3 name: t_scale_dataframe\n",
    "# --------------------------------------------------------\n",
    "# The following is performed:\n",
    "# --- scale a feature column, using the t-score scale. The t-distribution information is given as an input parameter.\n",
    "#     The scaling needs to be done for every column in the input dataframe. The function should return\n",
    "#     a dataframe with the same columns and indexes, but with the scaled values. \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - dataset - an input dataframe including both the X feature vectors and y categories to be scaled\n",
    "# - mean_std_dataframe - a dataframe including the mean and std for each column, to be used in scaling\n",
    "# ------------\n",
    "# return value:\n",
    "# - scaled dataset -  a dataframe containing the same columns and indexes, but with the scaled values.\n",
    "# ---------------------\n",
    "def t_scale_dataframe(dataset,mean_std_dataframe):\n",
    "    scaled_dataset = pd.DataFrame(index=dataset.index,columns=dataset.columns)\n",
    "    for col in dataset.columns:\n",
    "        scaled_dataset[col] = (dataset[col]-mean_std_dataframe[col]['mean'])/mean_std_dataframe[col]['std']\n",
    "    return scaled_dataset\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method4 name: t_descale_attr\n",
    "# ---------------------------\n",
    "# The following is performed:\n",
    "# --- de-scale (the opposite of scaling) the values of the input series, using the t-score scale.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - scaled_series -  a series containing scaled values.\n",
    "# - mean_std_series - a column from the mean_std_dataframe for descaling.\n",
    "# ------------\n",
    "# return value:\n",
    "# - de_scaled_series - a seires with the same indexes as the input series, containg the descaled values\n",
    "# --------------------------------------------------------\n",
    "def t_descale_series(scaled_series,mean_std_series):\n",
    "    return scaled_series*mean_std_series['std'] + mean_std_series['mean']\n",
    "    \n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"show usage of 't_scale_dataframe' output validation ...\\n\")\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "# ------\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "# ------\n",
    "\n",
    "scaled_dataset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "\n",
    "de_scaled_price_series = t_descale_series(scaled_dataset['price'],mean_std_dataframe['price'])\n",
    "print (\"train 'price' (head) values          ---> %r\" %(df_house_pricing_train['price'].head().tolist()))\n",
    "print (\"train 'price' scaled (head) values   ---> %s\" %('['+','.join(['%7.3f...' %(price) for price in scaled_dataset['price'].head().tolist()]) +']'))\n",
    "print (\"train 'price' descaled (head) values ---> %r\" %(de_scaled_price_series.head().tolist()))\n",
    "print (\"-------------------------\\n\")\n",
    "\n",
    "scaled_dataset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "de_scaled_size_series = t_descale_series(scaled_dataset['size'],mean_std_dataframe['size'])\n",
    "print (\"train 'size' (head) values          ---> %r\" %(df_house_pricing_train['size'].head().tolist()))\n",
    "print (\"train 'size' scaled (head) values   ---> %s\" %('['+','.join(['%7.3f...' %(price) for price in scaled_dataset['size'].head().tolist()]) +']'))\n",
    "print (\"train 'size' descaled (head) values ---> %r\" %(de_scaled_size_series.head().tolist()))\n",
    "#--------------------------\n",
    "df_house_pricing = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3c - add fictive attribute to x_feature_vector ----> run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dce25a9f77d2f88ed40fa8eb91c96c1e",
     "grade": false,
     "grade_id": "run-insert_fictive_attr",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following methods returns a copy of the input \n",
    "# dataframe, with an additional fictive feature, with a \n",
    "# constant value of 1\n",
    "# ---------------------\n",
    "# input parameter:\n",
    "# - x_feature_vectors - the input dataframe of the feature vectors\n",
    "# - fictive_attr_name - the name of the fictive feature. This feature will be added as a \n",
    "#                       first parameter and will be filled with values of 1.\n",
    "# ------------------\n",
    "# returned value:\n",
    "# x_FVs_w_fictive_attr - the copy of the dataframe, with the added column (of\n",
    "#                                  the fictive feature)\n",
    "def insert_fictive_attr_to_df(x_feature_vectors,fictive_attr_name):\n",
    "    x_FVs_w_fictive_attr = x_feature_vectors.copy()\n",
    "    x_FVs_w_fictive_attr.insert(loc=0,column=fictive_attr_name,value=1)\n",
    "    return x_FVs_w_fictive_attr\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"show usage of 'insert_fictive_attr_to_df' output validation ...\\n\")\n",
    "fictive_attr_name = 'fictive_0'\n",
    "\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "# ------\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "# ------\n",
    "print (\"show dataframe's first few rows (original feature vectors):\")\n",
    "print (X_train.head())\n",
    "print ('------------------\\n')\n",
    "print (\"show dataframe's first few rows (after adding the fictive attribute):\")\n",
    "x_FVs_w_fictive = insert_fictive_attr_to_df(X_train,fictive_attr_name)\n",
    "print (x_FVs_w_fictive.head())\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3d - multivariate linear regression  - predict ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Part 3d - multivariate linear regression  - predict </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>predict</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following method to calulate and return the multivariate linear regression prediction.\n",
    " Note: the 'predict' method should be used both for the predictions on the testset, as well as\n",
    "        interim steps in the training process.     \n",
    "------------\n",
    "input parameters:\n",
    "- x_feature_vectors - a dataframe containing all feature vectors for which we want to predict the y_hat values,\n",
    "                      using the multivariate linear regression model's weights.\n",
    "                 Note: it is expected the the x_feature_vectors contains a fictive column of features, with \n",
    "                       the constant value of 1, representing the x_0 fictive feature.\n",
    "- trained_w - the trained linear regression parameters w vector (or weights from some step in the training) .\n",
    "                 Note: it is expected the the trained_w series contains a fictive column, representing w_0.\n",
    "                       In this function you do not have to deal with this fact, but only multiple w series with\n",
    "                       each x feature vector (or with the whole matrix).\n",
    "------------\n",
    "return value:\n",
    "- y_hat - a series of the predictions for each input feature vector instances\n",
    "\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51183cc147a7918695c53dc80b652b2f",
     "grade": false,
     "grade_id": "predict-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1 \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: predict\n",
    "# --------------------------------------------------------\n",
    "def predict(x_featureVectors,trained_w):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d35cc81f1e17ef72d86fbd65aed7b2c",
     "grade": true,
     "grade_id": "test-predict",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#---------------------\n",
    "print (\"test #1 - basic test of 'predict' method for instances ...\\n\") \n",
    "#---------------------\n",
    "fictive_attr_name = 'fictive_0'\n",
    "\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "# ------\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "# ------\n",
    "scaled_trainset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "scaled_testset  = t_scale_dataframe(df_house_pricing_test,mean_std_dataframe)\n",
    "scaled_xTrain = scaled_trainset.drop('price',axis=1)\n",
    "scaled_yTrain = scaled_trainset['price']\n",
    "scaled_xTest  = scaled_testset.drop('price',axis=1)\n",
    "scaled_yTest  = scaled_testset['price']\n",
    "# ------\n",
    "fictive_attr_name = 'attr_0'\n",
    "xTest_w_fctv = insert_fictive_attr_to_df(X_test,fictive_attr_name)\n",
    "scaled_xTest_w_fctv = insert_fictive_attr_to_df(scaled_xTest,fictive_attr_name)\n",
    "w_vector = pd.Series(data=[300000, 30, 3000], index=xTest_w_fctv.columns)\n",
    "yHat = predict(xTest_w_fctv,w_vector)\n",
    "assert (int(yHat.iloc[0]/1000),int(yHat.iloc[2]/1000))==(347, 438), 'wrong values for predict'\n",
    "\n",
    "print (\"displaying house pricing data\")\n",
    "print (\"Note - the output linear regression line (based on the given w vector)\\n is not optimal and is only used for testing: \\n\")\n",
    "plotPointsAndPricingLine(X_test, y_test,yHat) \n",
    "\n",
    "print (\"\\n----> The 'predict' tests passed successfully :-) \\n\")\n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "scaled_xTrain,scaled_yTrain = None,None\n",
    "scaled_testset,scaled_xTest,scaled_yTest = None,None,None\n",
    "scaled_trainset,scaled_xTrain,scaled_yTrain = None,None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3e - multivariate linear regression training with gradient descent ----> total 4 points \n",
    "<img src='./images/multivariate_gradient_descent.png' alt=\"multivariate gradient-descent for linear regression\" style=\"width: 200x\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Part 3e - multivariate linear regression training with gradient descent </u> ----> needs stundent implementation - 4 points<br/>\n",
    "<u>method name</u>: <b>fit</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following method to train a multivariate (two or more features) linear regression model, \n",
    "using the gradient descent algorithm and returns the trained wight vector w.\n",
    "  Notes: \n",
    "        * at the beginning of the method there is a call to the method 'insert_fictive_attr_to_df'. \n",
    "          This returns a copy of the input feature vector dataframe, containing a fictive attribute.\n",
    "          This values of this fictive attribute are always 1. This is done in order to calculate it as\n",
    "          one of the features, so you do not need to differentiate between the regular coefficients (of the attributes),\n",
    "          and the free coefficient w_0.\n",
    "        * the indexes of the weight vector, which you create, should correspond to the column names, of the \n",
    "        'X_train_w_fictive_attr' dataframe returned from the 'insert_fictive_attr_to_df' method.\n",
    "        * note that the initial value of the weight vectors should be 0 for every attribute (including w_0).\n",
    "  Note also: you should use the predict method for interim prediction, during training.\n",
    "------------\n",
    "input parameters:\n",
    "- X_train - a dataframe containing all feature vectors of the train set.\n",
    "- y_train - a series of containing all class values per train instance.\n",
    "- fictive_attr_name - the name of the feature representing the x_0 fictive feature.\n",
    "         * This parameter is used in the call to the method 'insert_fictive_attr_to_df', described above.    \n",
    "- alpha - the learning rate\n",
    "- num_iterations - number of iterations to run multivariate gadient descent\n",
    "------------\n",
    "return value:\n",
    "- trained_w - a series containing the values of the vector of weights (w), \n",
    "              note: the indexes of the returned weight vector series, should correspond to the column names,\n",
    "                    of the 'X_train_w_fictive_attr' dataframe returned from the 'insert_fictive_attr_to_df' method.\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f723c998493c0559ab526a26557ec405",
     "grade": false,
     "grade_id": "fit-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: fit\n",
    "# --------------------------------------------------------\n",
    "def fit(X_train,y_train,fictive_attr_name,alpha,num_iterations):\n",
    "    # add a column, representing fictive x_0, so you could multiply the\n",
    "    # w vector with the x feature vectors at once (like taught in the class). The\n",
    "    # value of this fictive attribute, will always be one (so w_0 behaves like a free\n",
    "    # parameter). Do not change the following call:\n",
    "    X_train_w_fictive_attr = insert_fictive_attr_to_df(X_train, fictive_attr_name)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8893cd3c558956705c195bd4fe8a0aea",
     "grade": true,
     "grade_id": "test-fit",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "print (\"test #1 - test of the 'fit' method ...\\n\") \n",
    "\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "#---\n",
    "fictive_attr_name = 'attr_0'\n",
    "xTest_w_fctv = insert_fictive_attr_to_df(X_test,fictive_attr_name)\n",
    "#---\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "#---\n",
    "scaled_trainset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "scaled_testset  = t_scale_dataframe(df_house_pricing_test,mean_std_dataframe)\n",
    "#---\n",
    "scaled_xTrain = scaled_trainset.drop('price',axis=1)\n",
    "scaled_yTrain = scaled_trainset['price']\n",
    "scaled_xTest  = scaled_testset.drop('price',axis=1)\n",
    "scaled_yTest  = scaled_testset['price']\n",
    "#---\n",
    "fictive_attr_name = 'attr_0'\n",
    "scaled_xTest_w_fctv = insert_fictive_attr_to_df(scaled_xTest,fictive_attr_name)\n",
    "#---\n",
    "\n",
    "nWeights = X_train.shape[1] + 1\n",
    "alpha = 0.01\n",
    "num_iterations=1\n",
    "trained_w = fit(scaled_xTrain,scaled_yTrain,fictive_attr_name,alpha,num_iterations)\n",
    "assert int(trained_w[1]*1000)==15, 'wrong values for fit'\n",
    "print ('trained (1 epochs) w=%r, plot on test points: \\n' %(str(trained_w.tolist())))\n",
    "yHat = predict(scaled_xTest_w_fctv,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "#y_yhat = pd.DataFrame({'y':yTest,'yHat':de_scaled_yHat})\n",
    "plotPointsAndPricingLine(X_test, y_test,de_scaled_yHat)\n",
    "\n",
    "print (\"\\n----> Test #1 of the 'fit' method passed successfully :-) \\n\")\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "scaled_xTrain,scaled_yTrain = None,None\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46805e9ddd2bd5b09d11fe9bb681d125",
     "grade": true,
     "grade_id": "test2-fit",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------- \n",
    "print (\"test #2 - test of the 'fit' method ...\\n\") \n",
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "#---\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "#---\n",
    "scaled_trainset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "scaled_testset  = t_scale_dataframe(df_house_pricing_test,mean_std_dataframe)\n",
    "#---\n",
    "scaled_xTrain = scaled_trainset.drop('price',axis=1)\n",
    "scaled_yTrain = scaled_trainset['price']\n",
    "scaled_xTest  = scaled_testset.drop('price',axis=1)\n",
    "scaled_yTest  = scaled_testset['price']\n",
    "#---\n",
    "fictive_attr_name = 'attr_0'\n",
    "xTest_w_fctv = insert_fictive_attr_to_df(X_test,fictive_attr_name)\n",
    "scaled_xTest_w_fctv = insert_fictive_attr_to_df(scaled_xTest,fictive_attr_name)\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "num_iterations=10\n",
    "trained_w = fit(scaled_xTrain,scaled_yTrain,fictive_attr_name,alpha,num_iterations)\n",
    "\n",
    "assert int(trained_w[2]*1000)==61, 'wrong values for fit'\n",
    "print ('trained (10 epochs) w=%r\\n' %(str(trained_w.tolist())))\n",
    "yHat = predict(scaled_xTest_w_fctv,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "y_yhat = pd.DataFrame({'y':yTest,'yHat':de_scaled_yHat})\n",
    "plotPointsAndPricingLine(X_test, y_test,de_scaled_yHat)\n",
    "\n",
    "num_iterations=100\n",
    "alpha = 0.01\n",
    "trained_w = fit(scaled_xTrain,scaled_yTrain,fictive_attr_name,alpha,num_iterations)\n",
    "\n",
    "print ('trained (100 epochs) w=%r, plot on test points:\\n' %(str(trained_w.tolist())))\n",
    "yHat = predict(scaled_xTest_w_fctv,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "plotPointsAndPricingLine(X_test, y_test,de_scaled_yHat)\n",
    "print (\"\\n----> The 'fit' test passed successfully :-) \\n\")\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "trained_w0, trained_w1 = None,None\n",
    "train_set,test_set = None,None\n",
    "mean_std_dataframe = None\n",
    "scaled_dataset,de_scaled_size_series = None,None\n",
    "scaled_xTrain,scaled_yTrain = None,None\n",
    "#-------------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df908491a6e1d07ff119f692e32467ec",
     "grade": true,
     "grade_id": "test3-fit-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------- \n",
    "print (\"test #3 - test of the 'fit' method, this test is not visble to the students ...\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f6f9de34bf11b3a0d27e67d77e77477",
     "grade": true,
     "grade_id": "test4-fit-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------- \n",
    "print (\"test #4 - test of the 'fit' method, this test is not visble to the students ...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Part 4 - Evaluation - RMSE - Root Mean Square Error  ----> Student's implementation - total 1 point \n",
    "<img src=\"./images/RMSE.png\" alt=\"RMSE\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Part 4 - calculate RMSE (Root Mean Square Error) </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_rmse</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following method to check the RMSE (root mean squared error) as shown in the above image,\n",
    "  for running the predicted linear regression values compared to the actual test values.      \n",
    "------------\n",
    "input parameters:\n",
    "- y_test - the actual expected values\n",
    "- y_hat  - the predicted expected values    \n",
    "------------\n",
    "return value:\n",
    "- mse_val - mse (mean squared error) value\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b8b710fdd9668148f3590698efcf836",
     "grade": false,
     "grade_id": "calc_rmse-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_rmse\n",
    "# --------------------------------------------------------\n",
    "def calc_rmse(y,yPredicted):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f0fef60b04fc17131b94a8de0f9ff7c",
     "grade": true,
     "grade_id": "test-calc_rmse",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_rmse' method implementation \n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'calc_rmse' output validation ...\")\n",
    "\n",
    "df_house_pricing_train = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_train1.csv')\n",
    "df_house_pricing_test  = pd.read_csv('.'+os.sep+'data'+os.sep+'house_pricing_dataset_test1.csv')\n",
    "X_train = df_house_pricing_train.drop('price',axis=1)\n",
    "y_train = df_house_pricing_train['price']\n",
    "X_test  = df_house_pricing_test.drop('price',axis=1)\n",
    "y_test  = df_house_pricing_test['price']\n",
    "#---\n",
    "mean_std_dataframe = t_distibution(df_house_pricing_train)\n",
    "#---\n",
    "scaled_trainset = t_scale_dataframe(df_house_pricing_train,mean_std_dataframe)\n",
    "scaled_testset  = t_scale_dataframe(df_house_pricing_test,mean_std_dataframe)\n",
    "#---\n",
    "scaled_xTrain = scaled_trainset.drop('price',axis=1)\n",
    "scaled_yTrain = scaled_trainset['price']\n",
    "scaled_xTest  = scaled_testset.drop('price',axis=1)\n",
    "scaled_yTest  = scaled_testset['price']\n",
    "#---\n",
    "fictive_attr_name = 'attr_0'\n",
    "xTest_w_fctv = insert_fictive_attr_to_df(X_test,fictive_attr_name)\n",
    "scaled_xTest_w_fctv = insert_fictive_attr_to_df(scaled_xTest,fictive_attr_name)\n",
    "#---\n",
    "\n",
    "nWeights = X_train.shape[1] + 1\n",
    "alpha = 0.03\n",
    "num_iterations=10\n",
    "trained_w = fit(scaled_xTrain,scaled_yTrain,fictive_attr_name,alpha,num_iterations)\n",
    "yHat = predict(scaled_xTest_w_fctv,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "# calculate rmse in k$:\n",
    "rmse_descaled = calc_rmse(y_test/1000,de_scaled_yHat/1000)\n",
    "rmse_scaled   = calc_rmse(scaled_yTest,yHat)\n",
    "\n",
    "print('trained (10 epochs) rmse_descaled (rmse in k$): %5.1f k$' %(rmse_descaled))\n",
    "print('trained (10 epochs) rmse_scaled: %5.3f' %(rmse_scaled))\n",
    "print ('trained (10 epochs) w=%r, plot on test points: \\n' %(str(trained_w.tolist())))\n",
    "plotPointsAndPricingLine(X_test, y_test,de_scaled_yHat)\n",
    "\n",
    "\n",
    "num_iterations=100\n",
    "alpha = 0.03\n",
    "trained_w = fit(scaled_xTrain,scaled_yTrain,fictive_attr_name,alpha,num_iterations)\n",
    "yHat = predict(scaled_xTest_w_fctv,trained_w)\n",
    "de_scaled_yHat = t_descale_series(yHat,mean_std_dataframe['price'])\n",
    "# calculate mse in k$:\n",
    "rmse_descaled = calc_rmse(y_test/1000,de_scaled_yHat/1000)\n",
    "rmse_scaled   = calc_rmse(scaled_yTest,yHat)\n",
    "assert int(rmse_descaled)==67, 'wrong values for calc_rmse'\n",
    "print ('trained (100 epochs) w=%r, plot on test points:\\n' %(str(trained_w.tolist())))\n",
    "print('trained (100 epochs) rmse_descaled (rmse in k$): %5.1f k$' %(rmse_descaled))\n",
    "print('trained (100 epochs) rmse_scaled: %5.3f' %(rmse_scaled))\n",
    "\n",
    "plotPointsAndPricingLine(X_test, y_test,de_scaled_yHat)\n",
    "\n",
    "# -------\n",
    "print (\"----> The 'calc_rmse' test passed successfully :-) \\n\")\n",
    "print ('note: Additional Tests might be executed on our side')  \n",
    "\n",
    "#--------------------------\n",
    "df_1d_attr_target = None\n",
    "X_vectors, y_categories = None,None\n",
    "xTrain,xTest,yTrain,yTest = None,None,None,None\n",
    "x1TrainSeries,yHat = None,None\n",
    "#-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
