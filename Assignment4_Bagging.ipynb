{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Bagging (mandatory assignment)\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The submition - important notes\n",
    "### You must follow the rules described here, regarding assignment submission:  \n",
    "* <b> Work by yourself</b> and submit your own assignment, <b>no pairing</b> to other students\n",
    "* Test and save your assignment - <b>submit the last tested and saved version</b>\n",
    "* Work on the <b>original notebook</b> of the assignmen \n",
    "* do <b>NOT</b> submit an <b>empty assignment</b> \n",
    "* do <b>NOT add extra files</b> \n",
    "* submit <b>only</b> the <b>notebook (.ipynb)</b> file and <u>NOT a .py/.txt/.rar/.zip</u> file and so on\n",
    "* <b>do NOT change</b> the notebook file name \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spam vs. not-Spam Dataset\n",
    "<img src=\"./images/spam_or_not_spam.png\" alt=\"Spam vs. not-Spam\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the (Spam vs. not-Spam) dataset:\n",
    "* The dataset tags email messages as spam or not-spam.\n",
    "* Classes (=categories): there are two possible classes: not_spam, spam\n",
    "* Attributes (=features): there are 57 features, including two types of features:\n",
    "  * word frequencies - the feature name contains a word, with the suffix '_wordFreq' e.g.: 'make_wordFreq'  \n",
    "    * The word could appear 0 times in a specific email, once or a few times.\n",
    "    * The values of this feature could be between 0 and 1 (the frequency is relative).\n",
    "  * Capital Letter pattern attributes - 3 features regarding capital letter patterns. e.g.: 'capitalLet_long' - the length of the longest sequence of capital letters in the email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The assignment has to do with the (Spam vs. not-Spam) dataset\n",
    "* This assignment is a bigger assignment and is graded accordingly (20 points total)\n",
    "  * It includes different methods to implement, related to the Bagging algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignmet 4 (mandatory) - Bagging (total of 20 points)\n",
    "<u>The assignment consists of 6 parts</u>:<br/>\n",
    "* a preceding step - import packages\n",
    "* Part 1 - Student information methods ----> needs stundent implementation\n",
    "* Part 2 - load the dataset - total 1 point\n",
    "  * part 2a - load the 'spam vs not-spam' dataset ----> run only\n",
    "  * part 2b - change classes values from string to number ----> Student's implementation - total 1 point\n",
    "* Part 3 - decision stumps classifiction - auxiliary classes and methods - run only\n",
    "* Part 4 - Training  ----> needs stundent implementation - 10 points\n",
    "    * Part 4a - bootstrap ----> Student's implementation - total 6 points\n",
    "    * Part 4b - fit (main bagging train flow) ----> Student's implementation - total 4 points\n",
    "* Part 5 - Prediction ---> Student's implementation - maximum possible points: 5\n",
    "* Part 6 - Evaluation - maximum possible points: 4\n",
    "  * Part 6a - evaluate confusion matrix ----> Student's implementation - total 2 points\n",
    "  * Part 6b - evaluate precision  ----> Student's implementation - total 1 point\n",
    "  * Part 6c - evaluate recall     ----> Student's implementation - total 1 point  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 1 - Student information methods:</h3><br/>\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b><br/><br/>\n",
    "<table align='left'>\n",
    "    <tr><td>\n",
    "        <img src=\"./images/id-card.png\" alt=\"name and id\" width=\"150\" align='left'/>\n",
    "    </td></tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myName</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your full name (as a string)\n",
    "    For example: assume your name is John Smith, you should write:\n",
    "    return 'John Smith'\n",
    "------------\n",
    "return value:\n",
    "- your full name (as a string)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c595f11fc929d4b77957a0c4ea39ebf3",
     "grade": false,
     "grade_id": "myName-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myName\n",
    "# --------------------------------------------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # YOUR CODE HERE\n",
    "    return \"Hen Haim Someh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information methods</u>:<br/>\n",
    "<u>method name</u>: <b>myId</b><br/>\n",
    "<pre>\n",
    "The following is expected:\n",
    "--- the method needs to return your ID number (as an integer number)\n",
    "    For example: assume your ID number is 1234, you should write:\n",
    "    return 1234\n",
    "------------\n",
    "return value:\n",
    "- your ID number (as an integer number)\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the 'YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd86e2e5bd34dbc752e47c5a08f57496",
     "grade": false,
     "grade_id": "myId-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: myId\n",
    "# --------------------------------------------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    return 313468654"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 1 Student information method - test</u><br/>\n",
    "* Test of 'myName' and 'myId' methods implementation  \n",
    "* It tests the correctness their implementation\n",
    "\n",
    "<u>Important Notes</u>:<br/>\n",
    "* This test cell MUST NOT raise any exception\n",
    "* It must pass all tests \n",
    "* Do NOT change or delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4f3f12e6de7c8661645a6b3d7671695",
     "grade": false,
     "grade_id": "test-myName-myId",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test:\n",
    "## the 'myName' and the 'myId' methods implementation \n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 2 - Loading dataset - total 1 point</h3>\n",
    "        <ul style=\"list-style-type:circle;text-align:left;font-size:115%\">\n",
    "            <li>Part 2a - load the \"Spam vs. not Spam\" datasets - run only</li>\n",
    "            <li>Part 2b - change classes values from string to number ----> Student's implementation - total 1 point</li>\n",
    "        </ul>\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='left'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2a  - load the \"Spam vs. not Spam\" datasets - run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d57b41d8d30e8afb8fba3d98da53d606",
     "grade": false,
     "grade_id": "load-spam-dataset-run-only",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "### The Following section loads the spam vs. not spam dataset\n",
    "classColName = 'class'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "print ('Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "\n",
    "print('\\t* The train-set includes %d instances (aka feature vectors)' %(X_train.shape[0]))\n",
    "print('\\t* The test-set  includes %d instances (aka feature vectors)' %(X_test.shape[0]))\n",
    "print ('... done')\n",
    "print ('--------------------------------------------------------')\n",
    "# --------------------------------------------------------\n",
    "# display the spam vs. not spam class information:\n",
    "# --------------------------------------------------------\n",
    "spam_classes = np.unique(y_train_classes.values)\n",
    "print ('There are %d spam classes' %(len(spam_classes)))\n",
    "print ('spam classes: ' + str(spam_classes))\n",
    "print ('--------------------------------------------------------')\n",
    "# --------------------------------------------------------\n",
    "# display the feature information:\n",
    "# --------------------------------------------------------\n",
    "feature_names = [col for col in X_train.columns]\n",
    "print ('\\nThere are %d features in the feature set (each feature vector has a value for every feature)' %(len(feature_names)))\n",
    "print('Feature names: [' + ','.join(feature_names[:2]) + ',..,' + ','.join(feature_names[-2:]) + ']')\n",
    "print ('--------------------------------------------------------')\n",
    "# --------------------------------------------------------\n",
    "# display the first few rows of the dataset vectors:\n",
    "# --------------------------------------------------------\n",
    "print('\\nfirst few train feature vectors (and first few features):')\n",
    "print(X_train.iloc[:,:4].head())\n",
    "print('-------\\n\\nfirst few corresponding categories:')\n",
    "print(y_train_classes.head())\n",
    "print ('--------------------------------------------------------')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2b  - change classes values from string to number ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 2b - change classes values from string to number </u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>str_categories_to_nums</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return a pandas series of the categories\n",
    "with numeric values instead of the original string values.\n",
    "change the values as following:\n",
    "-      negative class (string) --> 0\n",
    "-      positive class (string) --> 1\n",
    "------------\n",
    "input parameters:\n",
    "- y_categories - a series containing the dataset's categories (could be train/test or other categories)\n",
    "- positive_class_name -   the name of the category (string) of the positive class.\n",
    "------------\n",
    "return value:\n",
    "- y_NumCategories - a series of containing all class values with numeric values per instance.\n",
    "notes (regarding output):\n",
    "* each cell value, which doesn't equal the positive_class_name parameter will be considered as negative and \n",
    "  recieve a value of 0 in the output series.\n",
    "* each cell value, which equals the positive_class_name parameter will  be considered as positive and\n",
    "  recieve a value of 1 in the output series.\n",
    "* You could NOT assume that the input positive_class_name parameter equals 'spam'    \n",
    "* The index (of the output series) should be the same as (the index of) the input series.\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66c2dc35b13b2d390623bb17586e859b",
     "grade": false,
     "grade_id": "str_categories_to_nums-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: str_categories_to_nums\n",
    "# --------------------------------------------------------\n",
    "def str_categories_to_nums(y_categories, positiveClassName):\n",
    "    # YOUR CODE HERE\n",
    "    y_NumCategories = []\n",
    "    \n",
    "    for i in range(0, len(y_categories)):\n",
    "        if (y_categories[i] == positiveClassName):\n",
    "            y_NumCategories.append(1)\n",
    "        else:\n",
    "            y_NumCategories.append(0)\n",
    "\n",
    "    return pd.Series(y_NumCategories, y_categories.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5ebfbe1361504c91d751eed09858c56",
     "grade": true,
     "grade_id": "str_categories_to_nums-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'str_categories_to_nums' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print (\"testing implementation of the 'str_categories_to_nums' method ...\\n\") \n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------- \n",
    "\n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "print ('Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "\n",
    "# --------------------- \n",
    "y_train_classes_numeric = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "# --------------------------------------------------------\n",
    "assert y_train_classes_numeric is not None, 'y_train_classes_numeric object not initialized'\n",
    "assert isinstance(y_train_classes_numeric, pd.Series), 'y_train_classes_numeric object is not a series'\n",
    "assert y_train_classes_numeric.empty == False, 'y_train_classes_numeric dataframe object is empty'\n",
    "assert sameIndexes(y_train_classes_numeric,y_train_classes), 'y_train_classes_numeric should share the same indexes as y_train_classes'\n",
    "assert allValidVals(np.unique(y_train_classes_numeric.values),(0,1)), 'classes should be only 0 or 1 (as an integer number)'\n",
    "num_str_positives     = y_train_classes.where(y_train_classes==positive_class_name).dropna().shape[0]\n",
    "num_numeric_positives = y_train_classes_numeric.where(y_train_classes_numeric==1).dropna().shape[0]\n",
    "num_numeric_negatives = y_train_classes_numeric.where(y_train_classes_numeric==0).dropna().shape[0]\n",
    "num_train_categories =  y_train_classes.shape[0]\n",
    "assert num_str_positives == num_numeric_positives, 'y_train_classes_numeric should have the same number of positives as y_train_classes' \n",
    "assert num_train_categories == num_numeric_positives+num_numeric_negatives, 'method did not work proparly, you must fix this method' \n",
    "print ('number of positives: %d, number of negative: %d' %(num_numeric_positives, num_numeric_negatives))\n",
    "\n",
    "allValidVals = None\n",
    "sameIndexes = None\n",
    "classColName = None\n",
    "positive_class_name = None\n",
    "folderName = None\n",
    "datasetNamePrefix = None\n",
    "train_set = None\n",
    "test_set = None\n",
    "X_train = None\n",
    "y_train_classes = None\n",
    "X_test = None\n",
    "y_test_classes = None\n",
    "num_str_positives = None\n",
    "num_numeric_positives = None\n",
    "num_numeric_positives = None\n",
    "num_numeric_negatives = None\n",
    "num_train_categories = None\n",
    "# -------------------------------------------------------- str_categories_to_nums\n",
    "# if no exception was thrown by this point, the student side tests were successful:\n",
    "print (\"\\n----> This 'str_categories_to_nums' test passed successfully :-) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 decision stumps (and other classification utilities) ----> run only\n",
    "<img src=\"./images/treeStumps.jpg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75e8ff789c9f13bbed53e29b38c33db8",
     "grade": false,
     "grade_id": "auxiliary_classes-run",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# auxiliary classes regarding classification\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class 1: DecisionStump\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- wraps an api for decision stumps, so we have a unified api\n",
    "# ------------\n",
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        self._decisionStump = DecisionTreeClassifier(max_depth=1)\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self._decisionStump.fit(X_train,y_train)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self._decisionStump.predict(X_test)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class2: ClassiferInstGen\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- utility classifier to generate objects of the classification algorithm class   \n",
    "# ------------\n",
    "class ClassiferInstGen():\n",
    "    def __init__(self,classifierPyClass):\n",
    "        self._classifierPyClass = classifierPyClass\n",
    "        \n",
    "    def getNewClassifierPyObj(self):\n",
    "        return self._classifierPyClass()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class3: BootstrapFeatureClassifer\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- container classifier to save model and bootstrap features    \n",
    "# ------------\n",
    "class BootstrapFeatureClassifer():\n",
    "    def __init__(self,trainModel,featureNames):\n",
    "        self.model = trainModel\n",
    "        self.featureNames = featureNames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad7d997912aaff327d158169ab5b9b3c",
     "grade": false,
     "grade_id": "auxiliary-methods-run",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    " \n",
    "# --------------------------------------------------------\n",
    "# auxiliary methods regarding classification\n",
    "# --------------------------------------------------------\n",
    "        \n",
    "    \n",
    "# --------------------------------------------------------\n",
    "# method name1: trainBootstrapedClassificationModel\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- trains a classification model which matches the sklearn API of fit and predict.\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_sampled_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# Note: the X_sampled_train, y_train parameters could be instance bootsraped, feature bootsraped, both or none\n",
    "# - classificationAlgo_pyClass - the python 'class' parameter of a classification algorithm \n",
    "#                                For instance, the above 'DecisionStump' class.\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter. Each call to: classificationAlgo_pyClass()\n",
    "#                                      creates a new object (also called instance of the class)\n",
    "#                                      of the type of the class.  \n",
    "# ------------\n",
    "# return value:\n",
    "# - featuresTrainModelObj - an object including trained model and feature names \n",
    "# --------------------- \n",
    "def trainBootstrapedClassificationModel(X_sampled_train, y_sampled_train,classificationAlgo_pyClass):\n",
    "    classiferInstGen = ClassiferInstGen(classificationAlgo_pyClass)\n",
    "    classificationObj = classiferInstGen.getNewClassifierPyObj()\n",
    "    classificationObj.fit(X_sampled_train, y_sampled_train)\n",
    "    featuresTrainModelObj = BootstrapFeatureClassifer(classificationObj,X_sampled_train.columns)\n",
    "    return featuresTrainModelObj\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: trainDecisionStumpModel\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- trains a Decision Stump classification model using the trainBootstrapedClassificationModel.\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_sampled_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_sampled_train - a series of containing all class values per train instance\n",
    "# Note: the X_sampled_train, y_train parameters could be instance bootsraped, feature bootsraped, both or none\n",
    "# ------------\n",
    "# return value:\n",
    "# - featuresTrainModelObj - an object including trained model and feature names \n",
    "# --------------------- \n",
    "def trainDecisionStumpModel(X_sampled_train, y_sampled_train):\n",
    "    return trainBootstrapedClassificationModel(X_sampled_train, y_sampled_train,DecisionStump)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name3: classifierPredict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- predict test examples using a classification model (which corresponds to sklearn classifier APIs)\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test -  a dataframe containing feature vectors of the test set\n",
    "# - classification_obj - trained classificaion model (which corresponds to sklearn classifier APIs)\n",
    "# ------------\n",
    "# return value:\n",
    "# - yHat - a series of the predictions for each test instance  \n",
    "# --------------------- trainBootstrapedFeatureModel(X_sampled_train, y_train,classificationAlgo_pyClass)\n",
    "def classifierPredict(X_test, featuresTrainModelObj):\n",
    "    X_adapted = X_test[featuresTrainModelObj.featureNames]\n",
    "    predictions = featuresTrainModelObj.model.predict(X_adapted)\n",
    "    yHat = pd.Series(data=predictions,index=X_test.index)\n",
    "    return yHat\n",
    "\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35c36e15a6ccc21b2542ca52c10c77dc",
     "grade": false,
     "grade_id": "prepare-decision-stump-examples",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "\n",
    "X_training1 = X_train.iloc[:100,:] \n",
    "y_training1 = y_train.iloc[:100]\n",
    "X_training2 = X_train.iloc[100:200,:] \n",
    "y_training2 = y_train.iloc[100:200]\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of auxiliary methods examples\n",
    "#### You will need to use these 2 methods during the training process:\n",
    "* trainDecisionStumpModel\n",
    "* classifierPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3703545edfd14c691d9d2681b036fd29",
     "grade": false,
     "grade_id": "usage-decision_stumps-train-predict",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# show usages of functions\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# example for: the 'trainDecisionStumpModel' method\n",
    "# You will need this function to train a decision stump model. \n",
    "# The following is usage examples:\n",
    "# --------------------------------------------------------\n",
    "decisionStumpModel1=trainDecisionStumpModel(X_training1, y_training1)\n",
    "decisionStumpModel2=trainDecisionStumpModel(X_training2, y_training2)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# example for: the 'classifierPredict' method\n",
    "# You will need this function to use the trained decision stump model, to predict a new model. \n",
    "# The following is usage examples:\n",
    "# --------------------------------------------------------\n",
    "print ('A few prediction examples:')\n",
    "nExamples=6\n",
    "y_hat1 = classifierPredict(X_test.iloc[:nExamples,:], decisionStumpModel1)\n",
    "y_hat2 = classifierPredict(X_test.iloc[:nExamples,:], decisionStumpModel2)\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, prediction(classifier1): %r, prediction(classifier2): %r' %(nInd,y_test.iloc[nInd],y_hat1.iloc[nInd],y_hat2.iloc[nInd]))\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c126a130fc6bb9f6d0977ba3645b9ec1",
     "grade": false,
     "grade_id": "post-process",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat1 = None\n",
    "y_hat2 = None\n",
    "X_training1 = None \n",
    "y_training1 = None\n",
    "X_training2 = None \n",
    "y_training2 = None\n",
    "classificationModel1=None\n",
    "classificationModel2=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Building a Bagging Classifier\n",
    "<img src=\"./images/bagging-classifier.jpeg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 -  Train a Bagging Classifier\n",
    "The following cells perform 2 methods:\n",
    "* part 4a - bootstraping ----> Student's implementation - total 6 points\n",
    "* part 4b - fit (the bagging main train flow) ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4a - bootstrap ----> Student's implementation - total 6 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Part 4a - bootstrap </u> ----> needs stundent implementation - 6 points<br/>\n",
    "<u>method name</u>: <b>bootstrap</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following method to sample the input dataframe uniformly.\n",
    "The sampeling could be done on the instances (the rows) or on the features (the columns) and\n",
    "is dependent on the input boolean parameter do_sample_columns.\n",
    "Notes:\n",
    "    * an instanse bootstrap is with replacements \n",
    "    * a feature bootstrap is without replacement, but is counted, i.e., if the same feature is selected twice, \n",
    "      there will be one less feature in the output. If it selected three times, there will be two less features\n",
    "      in the output and so on.\n",
    "    * the ratio regards to the relevant bootstrap type. If it is a feature bootstrap and we have 50 input features,\n",
    "      and the sample ratio is 0.5, we should expect 25 sampled feature columns the most.\n",
    "    * if the sample ratio equals 0 you should return None\n",
    "    * if the sample ratio is greater than one, you need to sample that amount of times. In case of instance selection,\n",
    "      you will have more feature vectors than the input feature vectors.\n",
    "        \n",
    "------------\n",
    "input parameters:\n",
    "- X_train - a dataframe containing a training dataset, containing all feature vectors in the train-set.\n",
    "               * note that the last column (called 'DONT_REMOVE') is a fictive column and it is used only for us.\n",
    "                 It should always appear in the output, and is not one of the columns being sampled (in \n",
    "                 case of feature bootstraping). It should not be counted as one of the columns.\n",
    "                 In case there are 51 columns in X_train, including 'DONT_REMOVE', and the sample ratio is 10%, \n",
    "                 you need to sample 5 (out of 50) columns and include also the 'DONT_REMOVE' column (total 6 columns\n",
    "                 in the output X_bootstraped in this case of feature bootstraping).\n",
    "                 It is only used for our test reasons. DO NOT REMOVE IT.\n",
    "- y_train - a series containing the coresponding (corresponding to X_train) training categories.\n",
    "- sampleRatio - a floating number, containing the ratio of the sampeling out of feature set,\n",
    "               * we will derive the number of instances/features from sampleRatio\n",
    "- do_sample_features -  a boolean variable. \n",
    "              * If do_sample_features equals True, you should perform \n",
    "                feature bootstrap.\n",
    "                  * The last column (called 'DONT_REMOVE') is not part of the sampeling \n",
    "                    and should not be included.\n",
    "                     * This means that the last column should always appear, and is not considered\n",
    "                       a real column,\n",
    "                       It is only used for trace reasons.\n",
    "              * If do_sample_features equals False, you should perform instance bootstrap.\n",
    "------------\n",
    "return values (comma seperated):\n",
    "- X_bootstraped - the output bootstraped dataframe.  \n",
    "              * Note that the last column (called 'DONT_REMOVE') is not part of the sampeling (in \n",
    "                 case of feature bootstraping) and should not be counted as one of the columns.\n",
    "                     * This means that the last column should always appear, and is not considered a real column,\n",
    "                       It is only used for trace reasons. DO NOT REMOVE IT. (removing it will fail the test)\n",
    "- y_bootstraped - the corresponding bootstrapted dataframe.\n",
    "                  * Note that in case of feature bootstraped, the y_train isn't sampled, and could be \n",
    "                    returned as y_train (w/o change).\n",
    "\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "242c4e92e7948ce6a79b0fd759e2a7a2",
     "grade": false,
     "grade_id": "bootstrap-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 6\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: bootstrap\n",
    "# --------------------------------------------------------\n",
    "def bootstrap(X_train, y_train, sampleRatio, do_sample_features):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    numberOfRows = X_train.shape[0]\n",
    "    numberofColumns = X_train.shape[1]\n",
    "   \n",
    "    if (do_sample_features == False):\n",
    "        numberOfSamples = int(sampleRatio * numberOfRows)\n",
    "        X_bootstraped = pd.DataFrame(columns = X_train.columns)\n",
    "        y_bootstraped = pd.Series()\n",
    "\n",
    "        for i in range(0, numberOfSamples):\n",
    "            randomIndex = random.randrange(0 ,numberOfRows - 1)\n",
    "            X_bootstraped.loc[i] = X_train.iloc[randomIndex]\n",
    "            y_bootstraped.loc[i] = y_train.iloc[randomIndex]\n",
    "    \n",
    "    else: #do_sample_features == True\n",
    "        columnList = X_train.columns.tolist()\n",
    "        numberOfSamples = int(sampleRatio * numberofColumns)\n",
    "        X_bootstraped = pd.DataFrame()\n",
    "        y_bootstraped = y_train \n",
    "        \n",
    "        for i in range(0, numberOfSamples):\n",
    "            randomIndex = random.randrange(0 ,numberofColumns - 1)\n",
    "            X_bootstraped.insert(i, columnList[randomIndex], X_train.iloc[:, randomIndex], allow_duplicates = True)\n",
    "\n",
    "        X_bootstraped.insert(i + 1, columnList[-1], X_train.iloc[:, -1])     \n",
    "        X_bootstraped = X_bootstraped.loc[:, ~X_bootstraped.columns.duplicated()]        \n",
    " \n",
    "    return (X_bootstraped, y_bootstraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "881c32d295a8552e8847e070c050a048",
     "grade": false,
     "grade_id": "noteDontRemove-run",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "dontRemoveCol = 'DONT_REMOVE'\n",
    "noteDontRemove = '''Error: the last column ('DONT_REMOVE') was removed (or sampled). \n",
    "This column is a fictive column and it is used only for us.\n",
    "It should always appear in the output, and is not one of the columns being sampled (in \n",
    "case of feature bootstraping). It should not be counted as one of the columns.\n",
    "In case there are 51 columns in X_train, including 'DONT_REMOVE', and the sample ratio is 10%, \n",
    "you need to sample 5 (out of 50) columns and include also the 'DONT_REMOVE' column (total 6 columns\n",
    "in the output X_bootstraped in this case of feature bootstraping).\n",
    "It is only used for our test reasons. DO NOT REMOVE IT.\n",
    "'''\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08616d327fd8c3f3a9a03df23b449314",
     "grade": true,
     "grade_id": "test-basic-for-instance",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "#---------------------\n",
    "print (\"test #1 - basic test of 'bootstrap' method for instances ...\\n\") \n",
    "#---------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------------------------------------------\n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t * Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "X_train_100 = X_train.iloc[:100,:]\n",
    "y_train_100 = y_train.iloc[:100]\n",
    "# ---------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "sampleRatio = 0.5\n",
    "do_sample_features = False\n",
    "X_trainSampled, y_trainSampled = bootstrap(X_train_100, y_train_100, sampleRatio,do_sample_features)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "assert X_trainSampled is not None, 'X_trainSampled object not initialized'\n",
    "assert y_trainSampled is not None, 'y_trainSampled object not initialized'\n",
    "assert isinstance(X_trainSampled, pd.DataFrame), 'X_trainSampled object is not a dataframe'\n",
    "assert isinstance(y_trainSampled, pd.Series), 'y_trainSampled object is not a series'\n",
    "assert X_trainSampled.empty == False, 'X_trainSampled dataframe object is empty'\n",
    "assert y_trainSampled.empty == False, 'y_trainSampled series object is empty'\n",
    "assert dontRemoveCol in X_trainSampled.columns, noteDontRemove\n",
    "assert sameIndexes(X_trainSampled,y_trainSampled), 'X_trainSampled should share the same indexes as y_trainSampled'\n",
    "assert allValidVals(np.unique(y_trainSampled.values),(0,1)), \"y_trainSampled's value should be only 0 or 1 (as an integer number)\"\n",
    "assert X_trainSampled.shape[0] == 50, 'X_trainSampled dataframe object should have 50 rows'\n",
    "assert y_trainSampled.shape[0] == 50, 'y_trainSampled series object should have 50 cells'\n",
    "assert X_trainSampled.shape[1] == X_train.shape[1], \"the features should not be sampled\"\n",
    "\n",
    "print (\"----> The basic test of 'bootstrap' for instances passed successfully :-) \\n\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# ----------------------\n",
    "# TEST POSTPROCESS \n",
    "# ----------------------\n",
    "classColName, positive_class_name, folderName, datasetNamePrefix = None, None, None, None\n",
    "train_set, test_set, y_train_classes, y_test_classes = None, None, None, None\n",
    "X_train, X_test, y_train, y_test= None, None, None, None\n",
    "X_train_100, y_train_100 = None, None\n",
    "sampleRatio, X_trainSampled, y_trainSampled = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e3efbcd9acac5fcf1e4863e152cd5bf",
     "grade": true,
     "grade_id": "bootstrap-test-basic-for-feature",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# ---------------------\n",
    "print (\"test #2 - basic test of 'bootstrap' method for features ...\\n\")\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------------------------------------------\n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t * Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "columns = X_train.columns\n",
    "print (\"\\t * note: we select 51 features, since one (the last one) is fictive, so total 50 to sample from\")\n",
    "columns_50 = [col for col in columns[-51:]]\n",
    "\n",
    "X_train_50 = X_train.loc[:,columns_50]\n",
    "sampleRatio = 0.5\n",
    "do_sample_features = True\n",
    "X_trainSampled, y_trainSampled = bootstrap(X_train_50, y_train, sampleRatio,do_sample_features)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "assert X_trainSampled is not None, 'X_trainSampled object not initialized'\n",
    "assert y_trainSampled is not None, 'y_trainSampled object not initialized'\n",
    "assert isinstance(X_trainSampled, pd.DataFrame), 'X_trainSampled object is not a dataframe'\n",
    "assert isinstance(y_trainSampled, pd.Series), 'y_trainSampled object is not a series'\n",
    "assert X_trainSampled.empty == False, 'X_trainSampled dataframe object is empty'\n",
    "assert y_trainSampled.empty == False, 'y_trainSampled series object is empty'\n",
    "assert dontRemoveCol in X_trainSampled.columns, noteDontRemove\n",
    "assert X_trainSampled.empty == False, 'X_trainSampled dataframe object is empty'\n",
    "assert sameIndexes(X_trainSampled,X_train), 'X_trainSampled should share the same indexes as X_train'\n",
    "assert X_trainSampled.shape[1] >10, 'X_trainSampled dataframe object has a wrong number of sampled features'\n",
    "\n",
    "print (\"----> The basic test of 'bootstrap' for features passed successfully :-) \\n\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# ----------------------\n",
    "# TEST POSTPROCESS \n",
    "# ----------------------\n",
    "classColName, positive_class_name, folderName, datasetNamePrefix = None, None, None, None\n",
    "train_set, test_set, y_train_classes, y_test_classes = None, None, None, None\n",
    "X_train, X_test, y_train, y_test= None, None, None, None\n",
    "X_train_50, columns, columns_50 = None, None, None\n",
    "sampleRatio, X_trainSampled, y_trainSampled = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ab7255b65ae0ae14ab1bb000d66f12d",
     "grade": true,
     "grade_id": "bootstrap-3-compound",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #3 - compound test of the 'bootstrap' method for instances and features ...\\n\")\n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "# --------------------------------------------------------\n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t* Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "columns = X_train.columns\n",
    "print (\"\\t* we select 51 features, since one (the last one) is fictive, so total 50 to sample from\")\n",
    "columns_50 = [col for col in columns[-51:]]\n",
    "X_train_100_50 = X_train.loc[:,columns_50].iloc[:100,:]\n",
    "y_train_100 = y_train.iloc[:100]\n",
    "# ---------------------------------\n",
    "sampleRatio = 0.5\n",
    "do_not_sample_features = False\n",
    "do_sample_features = True\n",
    "# ------------\n",
    "X_train_featureSampled, y_train_featureSampled = bootstrap(X_train_100_50, y_train_100, sampleRatio,do_sample_features)\n",
    "cols_featureSampled = [col for col in X_train_featureSampled.columns]\n",
    "# --------------------------------------------------------\n",
    "assert X_train_featureSampled is not None, 'X_train_featureSampled object not initialized'\n",
    "assert isinstance(X_train_featureSampled, pd.DataFrame), 'X_train_featureSampled object is not a dataframe'\n",
    "assert X_train_featureSampled.empty == False, 'X_train_featureSampled dataframe object is empty'\n",
    "assert y_train_featureSampled.empty == False, 'y_train_featureSampled dataframe object is empty'\n",
    "assert dontRemoveCol in X_train_featureSampled.columns, noteDontRemove\n",
    "assert sameIndexes(X_train_featureSampled,X_train_100_50), 'X_train_featureSampled should share the same indexes as X_train_100_50'\n",
    "assert sameIndexes(X_train_featureSampled,y_train_featureSampled), 'X_train_featureSampled should share the same indexes as y_train_featureSampled'\n",
    "assert allValidVals(np.unique(y_train_featureSampled.values),(0,1)), \"y_train_featureSampled's value should be only 0 or 1 (as an integer number)\"\n",
    "assert X_train_featureSampled.shape[1] >10, 'X_train_featureSampled dataframe object has a wrong number of sampled features'\n",
    "assert len(cols_featureSampled)==len(list(set(cols_featureSampled))),'duplications in columns after feature sampling'\n",
    "assert X_train_featureSampled[cols_featureSampled[3]].iloc[2]==X_train_100_50[cols_featureSampled[3]].iloc[2], \"'%s' feature value for 3rd row has changed\" %(cols_featureSampled[3])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "X_train_inst_attr_sampled, y_train_inst_attr_sampled = bootstrap(X_train_featureSampled, y_train_featureSampled, sampleRatio,do_not_sample_features)\n",
    "cols_inst_attr_sampled = [col for col in X_train_inst_attr_sampled.columns]\n",
    "# --------------------------------------------------------\n",
    "assert X_train_inst_attr_sampled is not None, 'X_train_inst_attr_sampled object not initialized'\n",
    "assert y_train_inst_attr_sampled is not None, 'y_train_inst_attr_sampled object not initialized'\n",
    "assert isinstance(X_train_inst_attr_sampled, pd.DataFrame), 'X_train_inst_attr_sampled object is not a dataframe'\n",
    "assert isinstance(y_train_inst_attr_sampled, pd.Series), 'y_train_inst_attr_sampled object is not a series'\n",
    "assert X_train_inst_attr_sampled.empty == False, 'X_train_inst_attr_sampled dataframe object is empty'\n",
    "assert y_train_inst_attr_sampled.empty == False, 'y_train_inst_attr_sampled series object is empty'\n",
    "assert dontRemoveCol in X_train_inst_attr_sampled.columns, noteDontRemove\n",
    "assert allValidVals(np.unique(y_train_inst_attr_sampled.values),(0,1)), \"y_train_inst_attr_sampled's value should be only 0 or 1 (as an integer number)\"\n",
    "assert X_train_inst_attr_sampled.shape[0] == 50, 'X_train_inst_attr_sampled dataframe object should have 50 rows'\n",
    "assert y_train_inst_attr_sampled.shape[0] == 50, 'y_train_inst_attr_sampled series object should have 50 cells'\n",
    "assert X_train_inst_attr_sampled.shape[1] == X_train_featureSampled.shape[1], \"the features should not be sampled\"\n",
    "for (dont_rem_nRow,nCol) in ((1,5),(5,3),(15,6),(20,9)):\n",
    "    dont_rem_val=X_train_inst_attr_sampled[dontRemoveCol].iloc[dont_rem_nRow]\n",
    "    assert X_train_inst_attr_sampled[cols_inst_attr_sampled[nCol]].iloc[dont_rem_nRow]==X_train_100_50.loc[X_train_100_50[dontRemoveCol]==dont_rem_val][cols_inst_attr_sampled[nCol]].iloc[0], \"'%s' feature value has changed\" %(cols_inst_attr_sampled[nCol])\n",
    "print (\"----> The compound test of 'bootstrap' for instances and features passed successfully :-) \\n\")\n",
    "# ----------------------\n",
    "# TEST POSTPROCESS \n",
    "# ----------------------\n",
    "classColName, positive_class_name, folderName, datasetNamePrefix = None, None, None, None\n",
    "train_set, test_set, y_train_classes, y_test_classes = None, None, None, None\n",
    "X_train, X_test, y_train, y_test= None, None, None, None\n",
    "columns, columns_50, X_train_100_50, y_train_100= None, None, None, None\n",
    "sampleRatio, do_not_sample_features, do_sample_features= None, None, None\n",
    "X_train_featureSampled, y_train_featureSampled, X_train_inst_attr_sampled, y_train_inst_attr_sampled = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44a56c04ad03de7d5d121f5a55645f82",
     "grade": true,
     "grade_id": "bootstrap-4-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "print (\"test #4 - test of the 'bootstrap' method, this test is not visble to the students ...\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6da756a2d94de381f9abf5a946d4fa8d",
     "grade": true,
     "grade_id": "bootstrap-5-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"test #5 - test of the 'bootstrap' method, this test is not visble to the students ...\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a95db797ff36a9ded55d0ba41b78d7",
     "grade": true,
     "grade_id": "bootstrap-6-hidden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"test #6 - test of the 'bootstrap' method, this test is not visble to the students ...\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 4c - fit (the bagging main flow) ----> Student's implementation - total 4 point:\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"200\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 4c -fit (the bagging main flow) </u> ----> needs stundent implementation - 4 points<br/>\n",
    "<u>method name</u>: <b>fit</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the a list of models created \n",
    "after bootstraping instances & features.\n",
    "------------\n",
    "input parameters:\n",
    "- X_train - a dataframe containing all feature vectors of the train set\n",
    "- y_train - a series of containing all class values per train instance\n",
    "- instanceSampleRatio - the ratio of the sampeling out of training set, \n",
    "                        * we will pass it on as a parameter, in order to sample instances.\n",
    "                        - if instanceSampleRatio<=0, no instance bootstrap is done, and we leave\n",
    "                          the training instances with no change.\n",
    "                        - a ratio >= 1 is valid\n",
    "- featureSampleRatio - the ratio of the sampeling out of feature set,\n",
    "                        * we will pass it on as a parameter, in order to sample features.\n",
    "                        - if featureSampleRatio<=0, no feature bootstrap is done, and we leave\n",
    "                          the features with no change.\n",
    "                        - a ratio >= 1 is valid\n",
    "\n",
    "- numModels - number of models to train in bagging\n",
    "* Note: the X_train, y_train parameters could be instance bootsraped, feature bootsraped or both            \n",
    "------------\n",
    "return value:\n",
    "- a (simple python) list of trained models \n",
    "note:\n",
    "        * the number of models are detrminded by the input parameter \n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6abe04d1a84618eb3cecb493a438182",
     "grade": false,
     "grade_id": "bagging-fit-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: fit\n",
    "# --------------------------------------------------------\n",
    "def fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels):\n",
    "    # note that FOR EACH bootstraped train set and/or feature set you need to create a classifier using:\n",
    "    # decisionStumpModel=trainDecisionStumpModel(X_train_bootstraped, y_train_corrolated_labels)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    trainedModels = []  \n",
    "    \n",
    "    for i in range(0, numModels):\n",
    "        \n",
    "        if (featureSampleRatio <= 0):\n",
    "            y_train_corrolated_labels = y_train\n",
    "            X_train_bootstraped = X_train\n",
    "        else: # featureSampleRatio > 0\n",
    "            X_train_bootstraped,y_train_corrolated_labels = bootstrap(X_train, y_train, featureSampleRatio, do_sample_features = True)\n",
    "            \n",
    "        if (instanceSampleRatio <= 0):\n",
    "            y_train_corrolated_labels = y_train\n",
    "            X_train_bootstraped = X_train\n",
    "        else: # instanceSampleRatio > 0\n",
    "            X_train_bootstraped,y_train_corrolated_labels = bootstrap(X_train, y_train, instanceSampleRatio, do_sample_features = False)\n",
    "        \n",
    "        decisionStumpModel = trainDecisionStumpModel(X_train_bootstraped, y_train_corrolated_labels)\n",
    "        trainedModels.append(decisionStumpModel)\n",
    "    \n",
    "    return trainedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51a6bba25a7e3242b6efb8a569e7bf92",
     "grade": true,
     "grade_id": "test-fit-1-basic-validity",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #1 - basic validity test of the 'fit' method ...\\n\")\n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t* Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 3\n",
    "baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"\\t * check basic 'fit' output validation ...\")\n",
    "assert baggedModels is not None, 'baggedModels object not initialized'\n",
    "assert isinstance(baggedModels, list), 'baggedModels object is not a list'\n",
    "assert None not in baggedModels, 'baggedModels should not include None elements'\n",
    "assert False not in [isinstance(elem,BootstrapFeatureClassifer) for elem in baggedModels], 'baggedModels should include only DecisionStump objects'\n",
    "\n",
    "print (\"\\n----> The #1 test of 'fit' passed successfully :-) \\n\")\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "687291fe8c0ce50971e5d91c954e07b0",
     "grade": true,
     "grade_id": "bagging-fit-test-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'fit' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #2 - compound test of the 'fit' method ...\\n\")\n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t* Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 3\n",
    "baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"\\t * check basic 'fit' output validation ...\")\n",
    "assert baggedModels is not None, 'baggedModels object not initialized'\n",
    "assert isinstance(baggedModels, list), 'baggedModels object is not a list'\n",
    "assert None not in baggedModels, 'baggedModels should not include None elements'\n",
    "assert False not in [isinstance(elem,BootstrapFeatureClassifer) for elem in baggedModels], 'baggedModels should include only DecisionStump objects'\n",
    "\n",
    "print ('trying to create inner bagged models prediction ...')\n",
    "nExamples=20\n",
    "y_hat_arr = [classifierPredict(X_test.iloc[:nExamples],model) for model in baggedModels]\n",
    "assert False not in [allValidVals(y_hat.values,(0,1)) for y_hat in y_hat_arr], 'something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "for nInd in range(nExamples):\n",
    "    predictions = '; '.join('[bag-model %d]: %r' %(nPred,y_hat_arr[nPred].iloc[nInd]) for nPred in range(len(y_hat_arr)))\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],predictions))\n",
    "\n",
    "print (\"\\n----> The #2 test of 'fit' passed successfully :-) \\n\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1688bc7b95c74e1338869a5049f3ed81",
     "grade": true,
     "grade_id": "bagging-fit-test-3-hidden",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'bootstrap' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"test #3 of the 'fit' method, this test is not visble to the students ...\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Prediction -  maximum possible points: 5\n",
    "The following cells perform the following:\n",
    "* step 1 - predict (voting)    ----> Student's implementation - total 3 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 5 -prediction </u> ----> needs stundent implementation - 5 points<br/>\n",
    "<u>method name</u>: <b>predict</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the predicted value for each test instance, \n",
    " based on the bagged trained models. You should return the majority class for\n",
    " each test instance.\n",
    "note: \n",
    "    * if there is not majrity, return None for that test instance\n",
    "      and print a message(this should not happen)\n",
    "# --------------------------------------------------------\n",
    "------------\n",
    "input parameters:\n",
    "- X_test -  a dataframe containing test feature vectors\n",
    "- baggingModels - the trained list of bagged models returned from 'fit' \n",
    "      (the output of the training process)\n",
    "------------\n",
    "return value:\n",
    "- y_hat - a series of the predictions, with the same index as X_test \n",
    "  note:\n",
    "        * the number of models are detrminded by the input parameter \n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85ad56eedcb99df2cf80fc79fcc3877c",
     "grade": false,
     "grade_id": "bagging-predict-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: predict\n",
    "# --------------------------------------------------------\n",
    "def predict(X_test, baggingModels):\n",
    "    # note that FOR EACH model in baggingModels, predict the value using:\n",
    "    # y_test=classifierPredict(X_test, baggingModel)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    classList = []\n",
    "    y_hat = pd.Series(X_test.index)\n",
    "    \n",
    "    for baggingModel in baggingModels:\n",
    "        y_test = classifierPredict(X_test, baggingModel)\n",
    "        classList.append(y_test)\n",
    "    \n",
    "    hDataFrame = pd.DataFrame(classList).transpose()\n",
    "    \n",
    "    for i in range(0, len(hDataFrame.index)):\n",
    "  \n",
    "        count = 0        \n",
    "        for j in range(0, len(hDataFrame.columns)):\n",
    "            if (hDataFrame.iloc[i][j] == 1):\n",
    "                count = count + 1\n",
    "            elif (hDataFrame.iloc[i][j] == 0):\n",
    "                count = count - 1 \n",
    "        \n",
    "        if (count < 0):\n",
    "            y_hat[i] = 0  \n",
    "        elif (count > 0):\n",
    "            y_hat[i] = 1\n",
    "        else: # count = 0\n",
    "            y_hat[i] = 'this should not happen'\n",
    "      \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0412fc3a6ac047ac178dcf5529706130",
     "grade": true,
     "grade_id": "predict-test-1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #1 - basic validity test of the 'predict' method ...\\n\")\n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t* Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"\\t * check basic 'predict' output validation ...\")\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 11\n",
    "baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "yHat = predict(X_test, baggedModels)\n",
    "assert yHat is not None, 'yHat object not initialized'\n",
    "assert isinstance(yHat, pd.Series), 'yHat object is not a pandas series'\n",
    "assert None not in yHat.values, 'yHat should not include None elements'\n",
    "assert allValidVals(yHat.values,(0,1)), 'prediction err - something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "nExamples = 20\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],yHat.iloc[nInd]))\n",
    "\n",
    "print (\"\\n----> The #1 test of 'predict' passed successfully :-) \\n\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "classColName, positive_class_name, folderName, datasetNamePrefix = None, None, None, None\n",
    "train_set, test_set, y_train_classes, y_test_classes = None, None, None, None\n",
    "X_train, X_test, y_train, y_test= None, None, None, None\n",
    "columns, columns_50, X_train_100_50, y_train_100= None, None, None, None\n",
    "sampleRatio1,sampleRatio2, sampleRatio3, do_not_sample_features, do_sample_features= None, None, None, None, None\n",
    "X_train_featureSampled1, y_train_featureSampled1, X_train_instSampled1, y_train_instSampled1= None, None, None, None\n",
    "X_train_featureSampled2, y_train_featureSampled2, X_train_instSampled2, y_train_instSampled2= None, None, None, None\n",
    "X_train_featureSampled3, y_train_featureSampled3, X_train_instSampled3, y_train_instSampled3= None, None, None, None\n",
    "X_train_featureSampled, y_train_featureSampled, X_train_inst_attr_sampled, y_train_inst_attr_sampled = None, None, None, None\n",
    "\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45753ac023d1e0cbeac3d899e0d4e9fb",
     "grade": true,
     "grade_id": "bagging-predict-test-2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'predict' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #2 - test of the 'predict' method, this test is not visble to the students ...\\n\") \n",
    "# --------------------- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Evaluation - maximum possible points: 4\n",
    "The following cells perform the following:\n",
    "* part 6a - evaluate confusion matrix ----> Student's implementation - total 2 points\n",
    "* part 6b - evaluate precision  ----> Student's implementation - total 1 point\n",
    "* part 6c - evaluate recall     ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6a - evaluate confusion matrix ----> needs stundent implementation - 2 points\n",
    "<img src=\"./images/confusion_matrix.jpg\" alt=\"confusion_matrix\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Part 6a - evaluate confusion matrix </u> ----> needs stundent implementation - 2 points <br/>\n",
    "<u>method name</u>: <b>calc_confusion_matrix</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return compute the 4 values of the confusion matrix: TN, FP, FN, TP\n",
    "Reminder:\n",
    "* TN - True Negative Count (model predicted 0, actual (test) result 0)\n",
    "* FP - False Positive Count (model predicted 1, actual (test) result 0)\n",
    "* FN - False Negative Count (model predicted 0, actual (test) result 1)\n",
    "* TP - True Positive Count (model predicted 1, actual (test) result 1)\n",
    "------------\n",
    "input parameters:\n",
    "- y_hat -  a series of containing all predicted class values per test instance\n",
    "- y_test - a series of containing all actual class values per test instance\n",
    "------------\n",
    "return values (comma seperated):\n",
    "- TN - True negatives - number of instances, for which the actual value (from y_test) \n",
    "                         is 0 (negative class, not_spam in our dataset) and \n",
    "                         the predicted value (from y_hat) is also 0.\n",
    "- FP - True negatives - number of instances, for which the actual value (from y_test) is 0, but \n",
    "                         the predicted value (from y_hat) is 1 (positive class, spam in our dataset).\n",
    "- FN - False negatives - number of instances, for which the actual value (from y_test) is 1, but                          \n",
    "                         the predicted value (from y_hat) is 0.\n",
    "- TP - False negatives - number of instances, for which the actual value (from y_test) is 1 and                          \n",
    "                         the predicted value (from y_hat) is also 1.\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52b9de87b20e4956395449535feaf294",
     "grade": false,
     "grade_id": "confusion-matrix-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_confusion_matrix\n",
    "# --------------------------------------------------------\n",
    "def calc_confusion_matrix(y_hat,y_test):\n",
    "    # YOUR CODE HERE\n",
    "    TN = len([1 for index in range(0, len(y_test)) if (y_test.iloc[index] == 0) and (y_hat.iloc[index] == 0)])\n",
    "    FP = len([1 for index in range(0, len(y_test)) if (y_test.iloc[index] == 0) and (y_hat.iloc[index] == 1)])\n",
    "    FN = len([1 for index in range(0, len(y_test)) if (y_test.iloc[index] == 1) and (y_hat.iloc[index] == 0)])\n",
    "    TP = len([1 for index in range(0, len(y_test)) if (y_test.iloc[index] == 1) and (y_hat.iloc[index] == 1)])\n",
    "    \n",
    "    return TN,FP,FN,TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e74746468b5f051c5967afead74963ab",
     "grade": true,
     "grade_id": "confusion-matrix-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_confusion_matrix' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #1 - test of the 'calc_confusion_matrix' method, this test is not visble to the students ...\\n\") \n",
    "# --------------------- \n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('\\t* Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "\n",
    "instanceSampleRatio = 0.5\n",
    "featureSampleRatio = 0.1\n",
    "numModels = 11\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "isTN_gt_750=False\n",
    "isTP_gt_300=False\n",
    "numTN,numFP,numFN,numTP = 0,0,0,0\n",
    "nTries = 10\n",
    "nTry=0\n",
    "for nTry in range(nTries):\n",
    "    nTry = nTry + 1\n",
    "    baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "    y_hat = predict(X_test, baggedModels)\n",
    "    numTN,numFP,numFN,numTP = calc_confusion_matrix(y_hat,y_test)\n",
    "    if numTN > 750:\n",
    "        isTN_gt_750 = True\n",
    "    if numTP > 300:\n",
    "        isTP_gt_300 = True\n",
    "    if isTN_gt_750 and isTP_gt_300:\n",
    "        break\n",
    "assert isTN_gt_750 and isTP_gt_300,'the True negatives and True positives is insufficient'\n",
    "print ('nTry:',nTry)\n",
    "print ('confusion matrix:')\n",
    "print ('\\tpred-0\\tpred-1')\n",
    "print ('is-0\\tTN=%d\\tFP=%d' %(numTN,numFP))\n",
    "print ('is-1\\tFN=%d\\tTP=%d' %(numFN,numTP))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "print (\"\\n----> The #1 test of 'calc_confusion_matrix' passed successfully :-) \\n\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25659c41eb7136c99b803568428d50f0",
     "grade": true,
     "grade_id": "confusion-matrix-test2-hiden",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_confusion_matrix' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #2 - test of the 'calc_confusion_matrix' method, this test is not visble to the students ...\\n\") \n",
    "# --------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6b - evaluate precision  ----> Student's implementation - total 1 point\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Part 6b - evaluate precision</u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_precision</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the precision for class 1 (spam in our dataset)\n",
    "------------\n",
    "input parameters:\n",
    "- y_hat -  a series of containing all predicted class values per test instance\n",
    "- y_test - a series of containing all actual class values per test instance\n",
    "------------\n",
    "return value\n",
    "- precision - float number containing precision value\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3d579511d9d21b3623452c728ea99c2",
     "grade": false,
     "grade_id": "precision-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_precision\n",
    "# --------------------------------------------------------\n",
    "def calc_precision(y_hat,y_test):\n",
    "    # YOUR CODE HERE\n",
    "    TN,FP,FN,TP = calc_confusion_matrix(y_hat, y_test)\n",
    "    precision = TP / (TP + FP)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3850087bf4f568c8dd2454b6a0397df",
     "grade": true,
     "grade_id": "precision-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_precision' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test of the 'calc_precision' method, this test is not visble to the students ...\\n\") \n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "\n",
    "instanceSampleRatio = 0.5\n",
    "featureSampleRatio = 0.1\n",
    "numModels = 5\n",
    "baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "yHat = predict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "print (\"\\t* check basic 'getPrecision' output validation ...\")\n",
    "precision = calc_precision(yHat,y_test)\n",
    "assert precision is not None, 'precision not initialized'\n",
    "assert precision>0, 'precision should not be 0'\n",
    "assert precision<=1, 'precision should not be more than 1 (=100%)'\n",
    "# --------------------------------------------------------\n",
    "precision = 0.0\n",
    "nTries = 10\n",
    "nTry=0\n",
    "isPrecision_gt_80=False\n",
    "for nTry in range(nTries):\n",
    "    nTry = nTry + 1\n",
    "    baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "    y_hat = predict(X_test, baggedModels)\n",
    "    precision = calc_precision(y_hat,y_test)\n",
    "    if precision>0.8:\n",
    "        isPrecision_gt_80=True \n",
    "        break\n",
    "assert isPrecision_gt_80,'the precision is too low'\n",
    "\n",
    "print ('nTry:', nTry)\n",
    "print ('pricision:', precision)\n",
    "\n",
    "print (\"\\n----> The test of 'calc_precision' passed successfully :-) \\n\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6c - evaluate recall     ----> Student's implementation - total 1 points\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Part 6c - evaluate recall</u> ----> needs stundent implementation - 1 point<br/>\n",
    "<u>method name</u>: <b>calc_recall</b><br/>\n",
    "\n",
    "<pre>\n",
    "Change the following function to return the recall for class 1 (spam in our dataset)\n",
    "------------\n",
    "input parameters:\n",
    "- y_hat -  a series of containing all predicted class values per test instance\n",
    "- y_test - a series of containing all actual class values per test instance\n",
    "------------\n",
    "return value\n",
    "- recall - float number containing recall value\n",
    "---------------------\n",
    "--- General notes:\n",
    "Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "In the line following the '# YOUR CODE HERE' line, add your code\n",
    "---------------------\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "#  - RUN AFTER IMPLEMENTATION (if used)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "962a02ffeaa3949fe0a94e4d4d784f27",
     "grade": false,
     "grade_id": "recall-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL - RUN AFTER IMPLEMENTATION\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: calc_recall\n",
    "# --------------------------------------------------------\n",
    "def calc_recall(y_hat,y_test):\n",
    "    # YOUR CODE HERE\n",
    "    TN,FP,FN,TP = calc_confusion_matrix(y_hat, y_test)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- internal-students-tests ---------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote(and disregard any tests you add).\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2883ca586dfab4c7ddf8d3ed2044e035",
     "grade": true,
     "grade_id": "recall-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL - DO NO CHANGE - RUN ONLY\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test the:\n",
    "## 'calc_recall' method implementation \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------- \n",
    "print (\"test #1 - test of the 'calc_recall' method, this test is not visble to the students ...\\n\") \n",
    "# --------------------- \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "\n",
    "# --------------------- \n",
    "classColName = 'class'\n",
    "positive_class_name = 'spam'\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetNamePrefix = folderName + os.sep + 'spam_notSpam'\n",
    "# --------------------- \n",
    "print ('Loading the spam vs. not spam train and test sets ...')\n",
    "train_set = pd.read_csv(datasetNamePrefix+'_train1.csv')\n",
    "test_set  = pd.read_csv(datasetNamePrefix+'_test1.csv')\n",
    "# --------------------- \n",
    "X_train = train_set.drop(classColName,axis=1)\n",
    "y_train_classes = train_set[classColName]\n",
    "X_test = test_set.drop(classColName,axis=1)\n",
    "y_test_classes = test_set[classColName]\n",
    "# --------------------- \n",
    "y_train = str_categories_to_nums(y_train_classes, positive_class_name)\n",
    "y_test = str_categories_to_nums(y_test_classes, positive_class_name)\n",
    "# --------------------- \n",
    "instanceSampleRatio = 0.5\n",
    "featureSampleRatio = 0.1\n",
    "numModels = 11\n",
    "baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "yHat = predict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'getRecall' output validation ...\")\n",
    "recall = calc_recall(yHat,y_test)\n",
    "assert recall is not None, 'precision not initialized'\n",
    "assert recall>0, 'recall should not be 0'\n",
    "assert recall<=1, 'recall should not be more than 1 (=100%)'\n",
    "# --------------------------------------------------------\n",
    "recall = 0.0\n",
    "nTries = 10\n",
    "nTry=0\n",
    "isRecall_gt_50=False\n",
    "for nTry in range(nTries):\n",
    "    nTry = nTry + 1\n",
    "    baggedModels =  fit(X_train, y_train, instanceSampleRatio, featureSampleRatio, numModels)\n",
    "    y_hat = predict(X_test, baggedModels)\n",
    "    recall = calc_recall(y_hat,y_test)\n",
    "    if recall>0.5:\n",
    "        isRecall_gt_50=True \n",
    "        break\n",
    "assert isRecall_gt_50,'the recall is too low'\n",
    "\n",
    "print ('nTry:', nTry)\n",
    "print ('recall:', recall)\n",
    "# --------------------------------------------------------\n",
    "print (\"\\n----> The #1 test of 'calc_recall' passed successfully :-) \\n\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
